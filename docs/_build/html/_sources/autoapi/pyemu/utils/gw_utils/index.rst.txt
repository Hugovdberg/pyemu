:mod:`pyemu.utils.gw_utils`
===========================

.. py:module:: pyemu.utils.gw_utils

.. autoapi-nested-parse::

   MODFLOW support utilities



Module Contents
---------------


Functions
~~~~~~~~~

.. autoapisummary::

   pyemu.utils.gw_utils.modflow_pval_to_template_file
   pyemu.utils.gw_utils.modflow_hob_to_instruction_file
   pyemu.utils.gw_utils.modflow_hydmod_to_instruction_file
   pyemu.utils.gw_utils.modflow_read_hydmod_file
   pyemu.utils.gw_utils.setup_mtlist_budget_obs
   pyemu.utils.gw_utils._write_mtlist_ins
   pyemu.utils.gw_utils.apply_mtlist_budget_obs
   pyemu.utils.gw_utils.setup_mflist_budget_obs
   pyemu.utils.gw_utils.apply_mflist_budget_obs
   pyemu.utils.gw_utils._write_mflist_ins
   pyemu.utils.gw_utils.setup_hds_timeseries
   pyemu.utils.gw_utils.apply_hds_timeseries
   pyemu.utils.gw_utils._setup_postprocess_hds_timeseries
   pyemu.utils.gw_utils._apply_postprocess_hds_timeseries
   pyemu.utils.gw_utils.setup_hds_obs
   pyemu.utils.gw_utils.last_kstp_from_kper
   pyemu.utils.gw_utils.apply_hds_obs
   pyemu.utils.gw_utils.setup_sft_obs
   pyemu.utils.gw_utils.apply_sft_obs
   pyemu.utils.gw_utils.setup_sfr_seg_parameters
   pyemu.utils.gw_utils.setup_sfr_reach_parameters
   pyemu.utils.gw_utils.apply_sfr_seg_parameters
   pyemu.utils.gw_utils.apply_sfr_parameters
   pyemu.utils.gw_utils.setup_sfr_obs
   pyemu.utils.gw_utils.apply_sfr_obs
   pyemu.utils.gw_utils.load_sfr_out
   pyemu.utils.gw_utils.setup_sfr_reach_obs
   pyemu.utils.gw_utils.apply_sfr_reach_obs
   pyemu.utils.gw_utils.modflow_sfr_gag_to_instruction_file
   pyemu.utils.gw_utils.setup_gage_obs
   pyemu.utils.gw_utils.apply_gage_obs
   pyemu.utils.gw_utils.apply_hfb_pars
   pyemu.utils.gw_utils.write_hfb_zone_multipliers_template
   pyemu.utils.gw_utils.write_hfb_template


.. data:: max_colwidth
   :annotation: = 100

   

.. data:: PP_FMT
   

   

.. data:: PP_NAMES
   :annotation: = ['name', 'x', 'y', 'zone', 'parval1']

   

.. function:: modflow_pval_to_template_file(pval_file, tpl_file=None)

   write a template file for a modflow parameter value file.

   :param pval_file: the path and name of the existing modflow pval file
   :type pval_file: `str`
   :param tpl_file: template file to write. If None, use
                    `pval_file` +".tpl". Default is None
   :type tpl_file: `str`, optional

   .. note:: Uses names in the first column in the pval file as par names.

   :returns: a dataFrame with control file parameter information
   :rtype: **pandas.DataFrame**


.. function:: modflow_hob_to_instruction_file(hob_file, ins_file=None)

   write an instruction file for a modflow head observation file

   :param hob_file: the path and name of the existing modflow hob file
   :type hob_file: `str`
   :param ins_file: the name of the instruction file to write.
                    If `None`, `hob_file` +".ins" is used.  Default is `None`.
   :type ins_file: `str`, optional

   :returns: a dataFrame with control file observation information
   :rtype: **pandas.DataFrame**


.. function:: modflow_hydmod_to_instruction_file(hydmod_file, ins_file=None)

   write an instruction file for a modflow hydmod file

   :param hydmod_file: the path and name of the existing modflow hob file
   :type hydmod_file: `str`
   :param ins_file: the name of the instruction file to write.
                    If `None`, `hydmod_file` +".ins" is used.  Default is `None`.
   :type ins_file: `str`, optional

   :returns: a dataFrame with control file observation information
   :rtype: **pandas.DataFrame**

   .. note:: calls `pyemu.gw_utils.modflow_read_hydmod_file()`


.. function:: modflow_read_hydmod_file(hydmod_file, hydmod_outfile=None)

   read a binary hydmod file and return a dataframe of the results

   :param hydmod_file: The path and name of the existing modflow hydmod binary file
   :type hydmod_file: `str`
   :param hydmod_outfile: output file to write.  If `None`, use `hydmod_file` +".dat".
                          Default is `None`.
   :type hydmod_outfile: `str`, optional

   :returns: a dataFrame with hymod_file values
   :rtype: **pandas.DataFrame**


.. function:: setup_mtlist_budget_obs(list_filename, gw_filename='mtlist_gw.dat', sw_filename='mtlist_sw.dat', start_datetime='1-1-1970', gw_prefix='gw', sw_prefix='sw', save_setup_file=False)

   setup observations of gw (and optionally sw) mass budgets from mt3dusgs list file.

   :param list_filename: path and name of existing modflow list file
   :type list_filename: `str`
   :param gw_filename: output filename that will contain the gw budget
                       observations. Default is "mtlist_gw.dat"
   :type gw_filename: `str`, optional
   :param sw_filename: output filename that will contain the sw budget
                       observations. Default is "mtlist_sw.dat"
   :type sw_filename: `str`, optional
   :param start_datetime: an str that can be parsed into a `pandas.TimeStamp`.
                          used to give budget observations meaningful names.  Default is "1-1-1970".
   :type start_datetime: `str`, optional
   :param gw_prefix: a prefix to add to the GW budget observations.
                     Useful if processing more than one list file as part of the forward run process.
                     Default is 'gw'.
   :type gw_prefix: `str`, optional
   :param sw_prefix: a prefix to add to the SW budget observations.  Useful
                     if processing more than one list file as part of the forward run process.
                     Default is 'sw'.
   :type sw_prefix: `str`, optional
   :param save_setup_file: a flag to save "_setup_"+ `list_filename` +".csv" file
                           that contains useful control file information.  Default is `False`.
   :type save_setup_file: `bool`, optional

   :returns: tuple containing

             - **str**:  the command to add to the forward run script
             - **str**: the names of the instruction files that were created
             - **pandas.DataFrame**: a dataframe with information for constructing a control file

   .. note::

      writes an instruction file and also a _setup_.csv to use when constructing a pest
          control file
      
      the instruction files are named `out_filename` +".ins"
      
      It is recommended to use the default value for `gw_filename` or `sw_filename`.
      
      This is the companion function of `gw_utils.apply_mtlist_budget_obs()`.


.. function:: _write_mtlist_ins(ins_filename, df, prefix)

   write an instruction file for a MT3D-USGS list file



.. function:: apply_mtlist_budget_obs(list_filename, gw_filename='mtlist_gw.dat', sw_filename='mtlist_sw.dat', start_datetime='1-1-1970')

   process an MT3D-USGS list file to extract mass budget entries.

   :param list_filename: the path and name of an existing MT3D-USGS list file
   :type list_filename: `str`
   :param gw_filename: the name of the output file with gw mass
                       budget information. Default is "mtlist_gw.dat"
   :type gw_filename: `str`, optional
   :param sw_filename: the name of the output file with sw mass budget information.
                       Default is "mtlist_sw.dat"
   :type sw_filename: `str`
   :param start_datatime: an str that can be cast to a pandas.TimeStamp.  Used to give
                          observations a meaningful name
   :type start_datatime: `str`

   :returns: 2-element tuple containing

             - **pandas.DataFrame**: the gw mass budget dataframe
             - **pandas.DataFrame**: (optional) the sw mass budget dataframe.
               If the SFT process is not active, this returned value is `None`.

   .. note:: this is the companion function of `gw_utils.setup_mtlist_budget_obs()`.


.. function:: setup_mflist_budget_obs(list_filename, flx_filename='flux.dat', vol_filename='vol.dat', start_datetime="1-1'1970", prefix='', save_setup_file=False)

   setup observations of budget volume and flux from modflow list file.

   :param list_filename: path and name of the existing modflow list file
   :type list_filename: `str`
   :param flx_filename: output filename that will contain the budget flux
                        observations. Default is "flux.dat"
   :type flx_filename: `str`, optional
   :param vol_filename: output filename that will contain the budget volume
                        observations.  Default is "vol.dat"
   :type vol_filename: `str`, optional
   :param start_datetime: a string that can be parsed into a pandas.TimeStamp.
                          This is used to give budget observations meaningful names.  Default is "1-1-1970".
   :type start_datetime: `str`, optional
   :param prefix: a prefix to add to the water budget observations.  Useful if
                  processing more than one list file as part of the forward run process. Default is ''.
   :type prefix: `str`, optional
   :param save_setup_file: a flag to save "_setup_"+ `list_filename` +".csv" file that contains useful
                           control file information
   :type save_setup_file: `bool`

   :returns: a dataframe with information for constructing a control file.
   :rtype: **pandas.DataFrame**

   .. note::

      This method writes instruction files and also a _setup_.csv to use when constructing a pest
      control file.  The instruction files are named <flux_file>.ins and <vol_file>.ins, respectively
      
      It is recommended to use the default values for flux_file and vol_file.
      
      This is the companion function of `gw_utils.apply_mflist_budget_obs()`.


.. function:: apply_mflist_budget_obs(list_filename, flx_filename='flux.dat', vol_filename='vol.dat', start_datetime='1-1-1970')

   process a MODFLOW list file to extract flux and volume water budget entries.

   :param list_filename: path and name of the existing modflow list file
   :type list_filename: `str`
   :param flx_filename: output filename that will contain the budget flux
                        observations. Default is "flux.dat"
   :type flx_filename: `str`, optional
   :param vol_filename: output filename that will contain the budget volume
                        observations.  Default is "vol.dat"
   :type vol_filename: `str`, optional
   :param start_datetime: a string that can be parsed into a pandas.TimeStamp.
                          This is used to give budget observations meaningful names.  Default is "1-1-1970".
   :type start_datetime: `str`, optional
   :param prefix: a prefix to add to the water budget observations.  Useful if
                  processing more than one list file as part of the forward run process. Default is ''.
   :type prefix: `str`, optional
   :param save_setup_file: a flag to save _setup_<list_filename>.csv file that contains useful
                           control file information
   :type save_setup_file: `bool`

    Note:
        this is the companion function of `gw_utils.setup_mflist_budget_obs()`.

    Returns:
        tuple containing


        - **pandas.DataFrame**: a dataframe with flux budget information
        - **pandas.DataFrame**: a dataframe with cumulative budget information



.. function:: _write_mflist_ins(ins_filename, df, prefix)

   write an instruction file for a MODFLOW list file



.. function:: setup_hds_timeseries(bin_file, kij_dict, prefix=None, include_path=False, model=None, postprocess_inact=None, text=None, fill=None, precision='single')

   a function to setup a forward process to extract time-series style values
   from a binary modflow binary file (or equivalent format - hds, ucn, sub, cbb, etc).

   :param bin_file: path and name of existing modflow binary file - headsave, cell budget and MT3D UCN supported.
   :type bin_file: `str`
   :param kij_dict: dictionary of site_name: [k,i,j] pairs. For example: `{"wel1":[0,1,1]}`.
   :type kij_dict: `dict`
   :param prefix: string to prepend to site_name when forming observation names.  Default is None
   :type prefix: `str`, optional
   :param include_path: flag to setup the binary file processing in directory where the hds_file
                        is located (if different from where python is running).  This is useful for setting up
                        the process in separate directory for where python is running.
   :type include_path: `bool`, optional
   :param model: a `flopy.basemodel` instance.  If passed, the observation names will
                 have the datetime of the observation appended to them (using the flopy `start_datetime` attribute.
                 If None, the observation names will have the zero-based stress period appended to them. Default is None.
   :type model: `flopy.mbase`, optional
   :param postprocess_inact: Inactive value in heads/ucn file e.g. mt.btn.cinit.  If `None`, no
                             inactive value processing happens.  Default is `None`.
   :type postprocess_inact: `float`, optional
   :param text: the text record entry in the binary file (e.g. "constant_head").
                Used to indicate that the binary file is a MODFLOW cell-by-cell budget file.
                If None, headsave or MT3D unformatted concentration file
                is assummed.  Default is None
   :type text: `str`
   :param fill: fill value for NaNs in the extracted timeseries dataframe.  If
                `None`, no filling is done, which may yield model run failures as the resulting
                processed timeseries CSV file (produced at runtime) may have missing values and
                can't be processed with the cooresponding instruction file.  Default is `None`.
   :type fill: `float`
   :param precision: the precision of the binary file.  Can be "single" or "double".
                     Default is "single".
   :type precision: `str`

   :returns: tuple containing

             - **str**: the forward run command to execute the binary file process during model runs.

             - **pandas.DataFrame**: a dataframe of observation information for use in the pest control file

   .. note::

      This function writes hds_timeseries.config that must be in the same
      dir where `apply_hds_timeseries()` is called during the forward run
      
      Assumes model time units are days
      
      this is the companion function of `gw_utils.apply_hds_timeseries()`.


.. function:: apply_hds_timeseries(config_file=None, postprocess_inact=None)

   process a modflow binary file using a previously written
   configuration file

   :param config_file: configuration file written by `pyemu.gw_utils.setup_hds_timeseries`.
                       If `None`, looks for `hds_timeseries.config`
   :type config_file: `str`, optional
   :param postprocess_inact: Inactive value in heads/ucn file e.g. mt.btn.cinit.  If `None`, no
                             inactive value processing happens.  Default is `None`.
   :type postprocess_inact: `float`, optional

   .. note:: this is the companion function of `gw_utils.setup_hds_timeseries()`.


.. function:: _setup_postprocess_hds_timeseries(hds_file, df, config_file, prefix=None, model=None)

   Dirty function to setup post processing concentrations in inactive/dry cells


.. function:: _apply_postprocess_hds_timeseries(config_file=None, cinact=1e+30)

   private function to post processing binary files


.. function:: setup_hds_obs(hds_file, kperk_pairs=None, skip=None, prefix='hds', text='head', precision='single', include_path=False)

   a function to setup using all values from a layer-stress period
   pair for observations.

   :param hds_file: path and name of an existing MODFLOW head-save file.
                    If the hds_file endswith 'ucn', then the file is treated as a UcnFile type.
   :type hds_file: `str`
   :param kperk_pairs: a list of len two tuples which are pairs of kper
                       (zero-based stress period index) and k (zero-based layer index) to
                       setup observations for.  If None, then all layers and stress period records
                       found in the file will be used.  Caution: a shit-ton of observations may be produced!
   :type kperk_pairs: [(int,int)]
   :param skip: a value or function used to determine which values
                to skip when setting up observations.  If np.scalar(skip)
                is True, then values equal to skip will not be used.
                If skip can also be a np.ndarry with dimensions equal to the model.
                Observations are set up only for cells with Non-zero values in the array.
                If not np.ndarray or np.scalar(skip), then skip will be treated as a lambda function that
                returns np.NaN if the value should be skipped.
   :type skip: variable, optional
   :param prefix: the prefix to use for the observation names. default is "hds".
   :type prefix: `str`
   :param text: the text tag the flopy HeadFile instance.  Default is "head"
   :type text: `str`
   :param precison: the precision string for the flopy HeadFile instance.  Default is "single"
   :type precison: `str`
   :param include_path: flag to setup the binary file processing in directory where the hds_file
   :type include_path: `bool`, optional
   :param is located: the process in separate directory for where python is running.
   :type is located: if different from where python is running

   :returns: tuple containing

             - **str**: the forward run script line needed to execute the headsave file observation
               operation
             - **pandas.DataFrame**: a dataframe of pest control file information

   .. note::

      Writes an instruction file and a _setup_ csv used construct a control file.
      
      This is the companion function to `gw_utils.apply_hds_obs()`.


.. function:: last_kstp_from_kper(hds, kper)

   function to find the last time step (kstp) for a
   give stress period (kper) in a modflow head save file.

   :param hds: head save file
   :type hds: `flopy.utils.HeadFile`
   :param kper: the zero-index stress period number
   :type kper: `int`

   :returns: the zero-based last time step during stress period
             kper in the head save file
   :rtype: **int**


.. function:: apply_hds_obs(hds_file, inact_abs_val=1e+20, precision='single', text='head')

   process a modflow head save file.  A companion function to
   `gw_utils.setup_hds_obs()` that is called during the forward run process

   :param hds_file: a modflow head save filename. if hds_file ends with 'ucn',
                    then the file is treated as a UcnFile type.
   :type hds_file: `str`
   :param inact_abs_val: the value that marks the mininum and maximum
                         active value.  values in the headsave file greater than `inact_abs_val` or less
                         than -`inact_abs_val` are reset to `inact_abs_val`
   :type inact_abs_val: `float`, optional

   :returns: a dataframe with extracted simulated values.
   :rtype: **pandas.DataFrame**

   .. note:: This is the companion function to `gw_utils.setup_hds_obs()`.


.. function:: setup_sft_obs(sft_file, ins_file=None, start_datetime=None, times=None, ncomp=1)

   writes a post-processor and instruction file for a mt3d-usgs sft output file

   :param sft_file: path and name of an existing sft output file (ASCII)
   :type sft_file: `str`
   :param ins_file: the name of the instruction file to create.
                    If None, the name is `sft_file`+".ins".  Default is `None`.
   :type ins_file: `str`, optional
   :param start_datetime: a pandas.to_datetime() compatible str.  If not None,
                          then the resulting observation names have the datetime
                          suffix.  If None, the suffix is the output totim.  Default
                          is `None`.
   :type start_datetime: `str`
   :param times: a list of times to make observations for.  If None, all times
                 found in the file are used. Default is None.
   :type times: [`float`]
   :param ncomp: number of components in transport model. Default is 1.
   :type ncomp: `int`

   .. note:: this is the companion function to `gw_utils.apply_sft_obs()`.

   :returns: a dataframe with observation names and values for the sft simulated
             concentrations.
   :rtype: **pandas.DataFrame**


.. function:: apply_sft_obs()

   process an mt3d-usgs sft ASCII output file using a previous-written
   config file

   :returns: a dataframe of extracted simulated outputs
   :rtype: **pandas.DataFrame**

   .. note:: this is the companion function to `gw_utils.setup_sft_obs()`.


.. function:: setup_sfr_seg_parameters(nam_file, model_ws='.', par_cols=None, tie_hcond=True, include_temporal_pars=None)

   Setup multiplier parameters for SFR segment data.

   :param nam_file: MODFLOw name file.  DIS, BAS, and SFR must be
                    available as pathed in the nam_file.  Optionally, `nam_file` can be
                    an existing `flopy.modflow.Modflow`.
   :type nam_file: `str`
   :param model_ws: model workspace for flopy to load the MODFLOW model from
   :type model_ws: `str`
   :param par_cols: a list of segment data entires to parameterize
   :type par_cols: [`str`]
   :param tie_hcond: flag to use same mult par for hcond1 and hcond2 for a
                     given segment.  Default is `True`.
   :type tie_hcond: `bool`
   :param include_temporal_pars: list of spatially-global multipliers to set up for
                                 each stress period.  Default is None
   :type include_temporal_pars: [`str`]

   :returns: a dataframe with useful parameter setup information
   :rtype: **pandas.DataFrame**

   .. note::

      This function handles the standard input case, not all the cryptic SFR options.  Loads the
         dis, bas, and sfr files with flopy using model_ws.

       This is the companion function to `gw_utils.apply_sfr_seg_parameters()` .

       The number (and numbering) of segment data entries must consistent across
           all stress periods.

       Writes `nam_file` +"_backup_.sfr" as the backup of the original sfr file

       Skips values = 0.0 since multipliers don't work for these


.. function:: setup_sfr_reach_parameters(nam_file, model_ws='.', par_cols=['strhc1'])

   Setup multiplier paramters for reach data, when reachinput option is specififed in sfr.


   :param nam_file: MODFLOw name file.  DIS, BAS, and SFR must be
                    available as pathed in the nam_file.  Optionally, `nam_file` can be
                    an existing `flopy.modflow.Modflow`.
   :type nam_file: `str`
   :param model_ws: model workspace for flopy to load the MODFLOW model from
   :type model_ws: `str`
   :param par_cols: a list of segment data entires to parameterize
   :type par_cols: [`str`]
   :param tie_hcond: flag to use same mult par for hcond1 and hcond2 for a
                     given segment.  Default is `True`.
   :type tie_hcond: `bool`
   :param include_temporal_pars: list of spatially-global multipliers to set up for
                                 each stress period.  Default is None
   :type include_temporal_pars: [`str`]

   :returns: a dataframe with useful parameter setup information
   :rtype: **pandas.DataFrame**

   .. note::

      Similar to `gw_utils.setup_sfr_seg_parameters()`, method will apply params to sfr reachdata
      
      Can load the dis, bas, and sfr files with flopy using model_ws. Or can pass a model object
          (SFR loading can be slow)
      
      This is the companion function of `gw_utils.apply_sfr_reach_parameters()`
      
      Skips values = 0.0 since multipliers don't work for these


.. function:: apply_sfr_seg_parameters(seg_pars=True, reach_pars=False)

   apply the SFR segement multiplier parameters.

   :param seg_pars: flag to apply segment-based parameters.
                    Default is True
   :type seg_pars: `bool`, optional
   :param reach_pars: flag to apply reach-based parameters.
                      Default is False
   :type reach_pars: `bool`, optional

   :returns: the modified SFR package instance
   :rtype: **flopy.modflow.ModflowSfr**

   .. note::

      expects "sfr_seg_pars.config" to exist
      
      expects `nam_file` +"_backup_.sfr" to exist


.. function:: apply_sfr_parameters(seg_pars=True, reach_pars=False)

   thin wrapper around `gw_utils.apply_sfr_seg_parameters()`

   :param seg_pars: flag to apply segment-based parameters.
                    Default is True
   :type seg_pars: `bool`, optional
   :param reach_pars: flag to apply reach-based parameters.
                      Default is False
   :type reach_pars: `bool`, optional

   :returns: the modified SFR package instance
   :rtype: **flopy.modflow.ModflowSfr**

   .. note::

      expects "sfr_seg_pars.config" to exist
      
      expects `nam_file` +"_backup_.sfr" to exist


.. function:: setup_sfr_obs(sfr_out_file, seg_group_dict=None, ins_file=None, model=None, include_path=False)

   setup observations using the sfr ASCII output file.  Setups
   the ability to aggregate flows for groups of segments.  Applies
   only flow to aquier and flow out.

   :param sft_out_file: the name and path to an existing SFR output file
   :type sft_out_file: `str`
   :param seg_group_dict: a dictionary of SFR segements to aggregate together for a single obs.
                          the key value in the dict is the base observation name. If None, all segments
                          are used as individual observations. Default is None
   :type seg_group_dict: `dict`
   :param model: a flopy model.  If passed, the observation names will have
                 the datetime of the observation appended to them.  If None, the observation names
                 will have the stress period appended to them. Default is None.
   :type model: `flopy.mbase`
   :param include_path: flag to prepend sfr_out_file path to sfr_obs.config.  Useful for setting up
                        process in separate directory for where python is running.
   :type include_path: `bool`

   :returns: dataframe of observation name, simulated value and group.
   :rtype: **pandas.DataFrame**

   .. note::

      This is the companion function of `gw_utils.apply_sfr_obs()`.
      
      This function writes "sfr_obs.config" which must be kept in the dir where
      "gw_utils.apply_sfr_obs()" is being called during the forward run


.. function:: apply_sfr_obs()

   apply the sfr observation process

   .. note::

      This is the companion function of `gw_utils.setup_sfr_obs()`.
      
      requires `sfr_obs.config`.
      
      Writes `sfr_out_file`+".processed", where `sfr_out_file` is defined in "sfr_obs.config"

   :returns: a dataframe of aggregrated sfr segment aquifer and outflow
   :rtype: **pandas.DataFrame**


.. function:: load_sfr_out(sfr_out_file, selection=None)

   load an ASCII SFR output file into a dictionary of kper: dataframes.

   :param sfr_out_file: SFR ASCII output file
   :type sfr_out_file: `str`
   :param selection: a dataframe of `reach` and `segment` pairs to
                     load.  If `None`, all reach-segment pairs are loaded.  Default is `None`.
   :type selection: `pandas.DataFrame`

   .. note::

      aggregates flow to aquifer for segments and returns and flow out at
      downstream end of segment.

   :returns: dictionary of {kper:`pandas.DataFrame`} of SFR output.
   :rtype: **dict**


.. function:: setup_sfr_reach_obs(sfr_out_file, seg_reach=None, ins_file=None, model=None, include_path=False)

   setup observations using the sfr ASCII output file.  Setups
   sfr point observations using segment and reach numbers.

   :param sft_out_file: the path and name of an existing SFR output file
   :type sft_out_file: `str`
   :param seg_reach: a dict, or list of SFR [segment,reach] pairs identifying
                     locations of interest.  If `dict`, the key value in the dict is the base
                     observation name. If None, all reaches are used as individual observations.
                     Default is None - THIS MAY SET UP A LOT OF OBS!
   :type seg_reach: varies
   :param model: a flopy model.  If passed, the observation names will
                 have the datetime of the observation appended to them.  If None, the
                 observation names will have the stress period appended to them. Default is None.
   :type model: `flopy.mbase`
   :param include_path: a flag to prepend sfr_out_file path to sfr_obs.config.  Useful
                        for setting up process in separate directory for where python is running.
   :type include_path: `bool`

   :returns: a dataframe of observation names, values, and groups
   :rtype: `pd.DataFrame`

   .. note::

      This is the companion function of `gw_utils.apply_sfr_reach_obs()`.
      
      This function writes "sfr_reach_obs.config" which must be kept in the dir where
      "apply_sfr_reach_obs()" is being called during the forward run


.. function:: apply_sfr_reach_obs()

   apply the sfr reach observation process.

   .. note::

      This is the companion function of `gw_utils.setup_sfr_reach_obs()`.
      
      Requires sfr_reach_obs.config.
      
      Writes <sfr_out_file>.processed, where <sfr_out_file> is defined in
      "sfr_reach_obs.config"

   :returns: a dataframe of sfr aquifer and outflow ad segment,reach locations
   :rtype: `pd.DataFrame`


.. function:: modflow_sfr_gag_to_instruction_file(gage_output_file, ins_file=None, parse_filename=False)

   writes an instruction file for an SFR gage output file to read Flow only at all times

   :param gage_output_file: the gage output filename (ASCII).
   :type gage_output_file: `str`
   :param ins_file: the name of the instruction file to
                    create.  If None, the name is `gage_output_file` +".ins".
                    Default is None
   :type ins_file: `str`, optional
   :param parse_filename: if True, get the gage_num parameter by
                          parsing the gage output file filename if False, get the gage
                          number from the file itself
   :type parse_filename: `bool`

   :returns: tuple containing

             - **pandas.DataFrame**: a dataframe with obsnme and obsval for the sfr simulated flows.
             - **str**: file name of instructions file relating to gage output.
             - **str**: file name of processed gage output for all times

   .. note::

      sets up observations for gage outputs only for the Flow column.
      
      If `parse_namefile` is true, only text up to first '.' is used as the gage_num


.. function:: setup_gage_obs(gage_file, ins_file=None, start_datetime=None, times=None)

   setup a forward run post processor routine for the modflow gage file

   :param gage_file: the gage output file (ASCII)
   :type gage_file: `str`
   :param ins_file: the name of the instruction file to create.  If None, the name
                    is `gage_file`+".processed.ins".  Default is `None`
   :type ins_file: `str`, optional
   :param start_datetime: a `pandas.to_datetime()` compatible `str`.  If not `None`,
                          then the resulting observation names have the datetime suffix.  If `None`,
                          the suffix is the output totim.  Default is `None`.
   :type start_datetime: `str`
   :param times: a container of times to make observations for.  If None,
                 all times are used. Default is None.
   :type times: [`float`]

   :returns: tuple containing

             - **pandas.DataFrame**: a dataframe with observation name and simulated values for the
               values in the gage file.
             - **str**: file name of instructions file that was created relating to gage output.
             - **str**: file name of processed gage output (processed according to times passed above.)

   .. note::

      setups up observations for gage outputs (all columns).
      
      This is the companion function of `gw_utils.apply_gage_obs()`


.. function:: apply_gage_obs(return_obs_file=False)

   apply the modflow gage obs post-processor

   :param return_obs_file: flag to return the processed
                           observation file.  Default is `False`.
   :type return_obs_file: `bool`

   .. note:: This is the companion function of `gw_utils.setup_gage_obs()`


.. function:: apply_hfb_pars(par_file='hfb6_pars.csv')

   a function to apply HFB multiplier parameters.

   :param par_file: the HFB parameter info file.
                    Default is `hfb_pars.csv`
   :type par_file: `str`

   .. note::

      This is the companion function to
      `gw_utils.write_hfb_zone_multipliers_template()`
      
      This is to account for the horrible HFB6 format that differs from other
      BCs making this a special case
      
      Requires "hfb_pars.csv"
      
      Should be added to the forward_run.py script


.. function:: write_hfb_zone_multipliers_template(m)

   write a template file for an hfb using multipliers per zone (double yuck!)

   :param m: a model instance with an HFB package
   :type m: `flopy.modflow.Modflow`

   :returns: tuple containing

             - **dict**: a dictionary with original unique HFB conductivity values and their
               corresponding parameter names
             - **str**: the template filename that was created


.. function:: write_hfb_template(m)

   write a template file for an hfb (yuck!)

   :param m: a model instance with an HFB package
   :type m: `flopy.modflow.Modflow`

    Returns:
        tuple containing

        - **str**: name of the template file that was created

        - **pandas.DataFrame**: a dataframe with use control file info for the
          HFB parameters



