:mod:`pyemu.utils`
==================

.. py:module:: pyemu.utils

.. autoapi-nested-parse::

   pyemu utils module contains lots of useful functions and
   classes, including support for geostatistical interpolation and
   covariance matrices, pilot point setup and processing and
   functionality dedicated to wrapping MODFLOW models into
   the PEST(++) model independent framework



Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   geostats/index.rst
   gw_utils/index.rst
   helpers/index.rst
   optimization/index.rst
   os_utils/index.rst
   pp_utils/index.rst
   pst_from/index.rst
   smp_utils/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   pyemu.utils.PstFromFlopyModel
   pyemu.utils.SpatialReference
   pyemu.utils.Cov
   pyemu.utils.GeoStruct
   pyemu.utils.SpecSim2d
   pyemu.utils.OrdinaryKrige
   pyemu.utils.Vario2d
   pyemu.utils.ExpVario
   pyemu.utils.GauVario
   pyemu.utils.SphVario
   pyemu.utils.PstFrom



Functions
~~~~~~~~~

.. autoapisummary::

   pyemu.utils.run
   pyemu.utils.start_workers
   pyemu.utils.geostatistical_draws
   pyemu.utils.geostatistical_prior_builder
   pyemu.utils._rmse
   pyemu.utils.calc_observation_ensemble_quantiles
   pyemu.utils.calc_rmse_ensemble
   pyemu.utils._condition_on_par_knowledge
   pyemu.utils.kl_setup
   pyemu.utils._eigen_basis_to_factor_file
   pyemu.utils.kl_apply
   pyemu.utils.zero_order_tikhonov
   pyemu.utils._regweight_from_parbound
   pyemu.utils.first_order_pearson_tikhonov
   pyemu.utils.simple_tpl_from_pars
   pyemu.utils.simple_ins_from_obs
   pyemu.utils.pst_from_parnames_obsnames
   pyemu.utils.read_pestpp_runstorage
   pyemu.utils.jco_from_pestpp_runstorage
   pyemu.utils.parse_dir_for_io_files
   pyemu.utils.pst_from_io_files
   pyemu.utils.apply_list_and_array_pars
   pyemu.utils._process_chunk_fac2real
   pyemu.utils._process_chunk_model_files
   pyemu.utils._process_model_file
   pyemu.utils.apply_array_pars
   pyemu.utils.apply_list_pars
   pyemu.utils.apply_genericlist_pars
   pyemu.utils.write_const_tpl
   pyemu.utils.write_grid_tpl
   pyemu.utils.write_zone_tpl
   pyemu.utils.build_jac_test_csv
   pyemu.utils._write_df_tpl
   pyemu.utils.setup_fake_forward_run
   pyemu.utils.setup_temporal_diff_obs
   pyemu.utils.apply_temporal_diff_obs
   pyemu.utils.get_maha_obs_summary
   pyemu.utils._l2_maha_worker
   pyemu.utils.pp_file_to_dataframe
   pyemu.utils.read_struct_file
   pyemu.utils._read_variogram
   pyemu.utils._read_structure_attributes
   pyemu.utils.read_sgems_variogram_xml
   pyemu.utils.gslib_2_dataframe
   pyemu.utils.load_sgems_exp_var
   pyemu.utils.fac2real
   pyemu.utils._parse_factor_line
   pyemu.utils.SFMT
   pyemu.utils.run
   pyemu.utils._write_df_tpl
   pyemu.utils.setup_pilotpoints_grid
   pyemu.utils.pp_file_to_dataframe
   pyemu.utils.pp_tpl_to_dataframe
   pyemu.utils.write_pp_shapfile
   pyemu.utils.write_pp_file
   pyemu.utils.pilot_points_to_tpl
   pyemu.utils.SFMT
   pyemu.utils.parse_tpl_file
   pyemu.utils.try_process_output_file
   pyemu.utils.run
   pyemu.utils._write_df_tpl
   pyemu.utils.modflow_pval_to_template_file
   pyemu.utils.modflow_hob_to_instruction_file
   pyemu.utils.modflow_hydmod_to_instruction_file
   pyemu.utils.modflow_read_hydmod_file
   pyemu.utils.setup_mtlist_budget_obs
   pyemu.utils._write_mtlist_ins
   pyemu.utils.apply_mtlist_budget_obs
   pyemu.utils.setup_mflist_budget_obs
   pyemu.utils.apply_mflist_budget_obs
   pyemu.utils._write_mflist_ins
   pyemu.utils.setup_hds_timeseries
   pyemu.utils.apply_hds_timeseries
   pyemu.utils._setup_postprocess_hds_timeseries
   pyemu.utils._apply_postprocess_hds_timeseries
   pyemu.utils.setup_hds_obs
   pyemu.utils.last_kstp_from_kper
   pyemu.utils.apply_hds_obs
   pyemu.utils.setup_sft_obs
   pyemu.utils.apply_sft_obs
   pyemu.utils.setup_sfr_seg_parameters
   pyemu.utils.setup_sfr_reach_parameters
   pyemu.utils.apply_sfr_seg_parameters
   pyemu.utils.apply_sfr_parameters
   pyemu.utils.setup_sfr_obs
   pyemu.utils.apply_sfr_obs
   pyemu.utils.load_sfr_out
   pyemu.utils.setup_sfr_reach_obs
   pyemu.utils.apply_sfr_reach_obs
   pyemu.utils.modflow_sfr_gag_to_instruction_file
   pyemu.utils.setup_gage_obs
   pyemu.utils.apply_gage_obs
   pyemu.utils.apply_hfb_pars
   pyemu.utils.write_hfb_zone_multipliers_template
   pyemu.utils.write_hfb_template
   pyemu.utils._istextfile
   pyemu.utils._remove_readonly
   pyemu.utils.run
   pyemu.utils.start_workers
   pyemu.utils.smp_to_ins
   pyemu.utils.dataframe_to_smp
   pyemu.utils._date_parser
   pyemu.utils.smp_to_dataframe
   pyemu.utils._get_datetime_from_str
   pyemu.utils._check_var_len
   pyemu.utils.write_list_tpl
   pyemu.utils._write_direct_df_tpl
   pyemu.utils._get_tpl_or_ins_df
   pyemu.utils.write_array_tpl
   pyemu.utils._check_diff


.. data:: max_colwidth
   :annotation: = 100

   

.. py:exception:: PyemuWarning

   Bases: :class:`RuntimeWarning`

   Base class for warnings about dubious runtime behavior.


.. function:: run(cmd_str, cwd='.', verbose=False)

   an OS agnostic function to execute a command line

   :param cmd_str: the str to execute with `os.system()`
   :type cmd_str: `str`
   :param cwd: the directory to execute the command in.
               Default is ".".
   :type cwd: `str`, optional
   :param verbose: flag to echo to stdout the  `cmd_str`.
                   Default is `False`.
   :type verbose: `bool`, optional

   .. rubric:: Notes

   uses `platform` to detect OS and adds .exe suffix or ./ prefix as appropriate
   if `os.system` returns non-zero, an exception is raised

   Example::

       pyemu.os_utils.run("pestpp-ies my.pst",cwd="template")


.. function:: start_workers(worker_dir, exe_rel_path, pst_rel_path, num_workers=None, worker_root='..', port=4004, rel_path=None, local=True, cleanup=True, master_dir=None, verbose=False, silent_master=False, reuse_master=False)

   start a group of pest(++) workers on the local machine

   :param worker_dir: the path to a complete set of input files need by PEST(++).
                      This directory will be copied to make worker (and optionally the master)
                      directories
   :type worker_dir: `str`
   :param exe_rel_path: the relative path to and name of the pest(++) executable from within
                        the `worker_dir`.  For example, if the executable is up one directory from
                        `worker_dir`, the `exe_rel_path` would be `os.path.join("..","pestpp-ies")`
   :type exe_rel_path: `str`
   :param pst_rel_path: the relative path to and name of the pest control file from within
                        `worker_dir`.
   :type pst_rel_path: `str`
   :param num_workers: number of workers to start. defaults to number of cores
   :type num_workers: `int`, optional
   :param worker_root: the root directory to make the new worker directories in.
                       Default is ".."  (up one directory from where python is running).
   :type worker_root: `str`, optional
   :param rel_path: the relative path to where pest(++) should be run
                    from within the worker_dir, defaults to the uppermost level of the worker dir.
                    This option is usually not needed unless you are one of those crazy people who
                    spreads files across countless subdirectories.
   :type rel_path: `str`, optional
   :param local: flag for using "localhost" instead of actual hostname/IP address on
                 worker command line. Default is True
   :type local: `bool`, optional
   :param cleanup: flag to remove worker directories once processes exit. Default is
                   True.  Set to False for debugging issues
   :type cleanup: `bool`, optional
   :param master_dir: name of directory for master instance.  If `master_dir`
                      exists, then it will be REMOVED!!!  If `master_dir`, is None,
                      no master instance will be started.  If not None, a copy of `worker_dir` will be
                      made into `master_dir` and the PEST(++) executable will be started in master mode
                      in this directory. Default is None
   :type master_dir: `str`
   :param verbose: flag to echo useful information to stdout.  Default is False
   :type verbose: `bool`, optional
   :param silent_master: flag to pipe master output to devnull and instead print
                         a simple message to stdout every few seconds.  This is only for
                         pestpp Travis testing so that log file sizes dont explode. Default is False
   :type silent_master: `bool`, optional
   :param reuse_master: flag to use an existing `master_dir` as is - this is an advanced user
                        option for cases where you want to construct your own `master_dir` then have an async
                        process started in it by this function.
   :type reuse_master: `bool`

   .. rubric:: Notes

   if all workers (and optionally master) exit gracefully, then the worker
       dirs will be removed unless `cleanup` is False

   Example::

       # start 10 workers using the directory "template" as the base case and
       # also start a master instance in a directory "master".
       pyemu.helpers.start_workers("template","pestpp-ies","pest.pst",10,master_dir="master")


.. function:: geostatistical_draws(pst, struct_dict, num_reals=100, sigma_range=4, verbose=True, scale_offset=True)

   construct a parameter ensemble from a prior covariance matrix
   implied by geostatistical structure(s) and parameter bounds.

   :param pst: a control file (or the name of control file).  The
               parameter bounds in `pst` are used to define the variance of each
               parameter group.
   :type pst: `pyemu.Pst`
   :param struct_dict: a dict of GeoStruct (or structure file), and list of
                       pilot point template files pairs. If the values in the dict are
                       `pd.DataFrames`, then they must have an 'x','y', and 'parnme' column.
                       If the filename ends in '.csv', then a pd.DataFrame is loaded,
                       otherwise a pilot points file is loaded.
   :type struct_dict: `dict`
   :param num_reals: number of realizations to draw.  Default is 100
   :type num_reals: `int`, optional
   :param sigma_range: a float representing the number of standard deviations
                       implied by parameter bounds. Default is 4.0, which implies 95% confidence parameter bounds.
   :type sigma_range: `float`
   :param verbose: flag to control output to stdout.  Default is True.
                   flag for stdout.
   :type verbose: `bool`, optional
   :param scale_offset: flag to apply scale and offset to parameter bounds
                        when calculating variances - this is passed through to `pyemu.Cov.from_parameter_data()`.
                        Default is True.
   :type scale_offset: `bool`,optional

   Returns
       `pyemu.ParameterEnsemble`: the realized parameter ensemble.

   .. note::

      parameters are realized by parameter group.  The variance of each
      parameter group is used to scale the resulting geostatistical
      covariance matrix Therefore, the sill of the geostatistical structures
      in `struct_dict` should be 1.0

   Example::

       pst = pyemu.Pst("my.pst")
       sd = {"struct.dat":["hkpp.dat.tpl","vka.dat.tpl"]}
       pe = pyemu.helpers.geostatistical_draws(pst,struct_dict=sd}
       pe.to_csv("my_pe.csv")



.. function:: geostatistical_prior_builder(pst, struct_dict, sigma_range=4, verbose=False, scale_offset=False)

   construct a full prior covariance matrix using geostastical structures
   and parameter bounds information.

   :param pst: a control file instance (or the name of control file)
   :type pst: `pyemu.Pst`
   :param struct_dict: a dict of GeoStruct (or structure file), and list of
                       pilot point template files pairs. If the values in the dict are
                       `pd.DataFrames`, then they must have an 'x','y', and 'parnme' column.
                       If the filename ends in '.csv', then a pd.DataFrame is loaded,
                       otherwise a pilot points file is loaded.
   :type struct_dict: `dict`
   :param sigma_range: a float representing the number of standard deviations
                       implied by parameter bounds. Default is 4.0, which implies 95% confidence parameter bounds.
   :type sigma_range: `float`
   :param verbose: flag to control output to stdout.  Default is True.
                   flag for stdout.
   :type verbose: `bool`, optional
   :param scale_offset: a flag to apply scale and offset to parameter upper and lower bounds
                        before applying log transform.  Passed to pyemu.Cov.from_parameter_data().  Default
                        is False
   :type scale_offset: `bool`

   :returns: a covariance matrix that includes all adjustable parameters in the control
             file.
   :rtype: `pyemu.Cov`

   .. note::

      The covariance of parameters associated with geostatistical structures is defined
      as a mixture of GeoStruct and bounds.  That is, the GeoStruct is used to construct a
      pyemu.Cov, then the entire pyemu.Cov is scaled by the uncertainty implied by the bounds and
      sigma_range. Most users will want to sill of the geostruct to sum to 1.0 so that the resulting
      covariance matrices have variance proportional to the parameter bounds. Sounds complicated...

   Example::

       pst = pyemu.Pst("my.pst")
       sd = {"struct.dat":["hkpp.dat.tpl","vka.dat.tpl"]}
       cov = pyemu.helpers.geostatistical_draws(pst,struct_dict=sd}
       cov.to_binary("prior.jcb")


.. function:: _rmse(v1, v2)

   return root mean squared error between v1 and v2

   :param v1: one vector
   :type v1: iterable
   :param v2: another vector
   :type v2: iterable

   :returns: root mean squared error of v1,v2
   :rtype: scalar


.. function:: calc_observation_ensemble_quantiles(ens, pst, quantiles, subset_obsnames=None, subset_obsgroups=None)

   Given an observation ensemble, and requested quantiles, this function calculates the requested
      quantile point-by-point in the ensemble. This resulting set of values does not, however, correspond
      to a single realization in the ensemble. So, this function finds the minimum weighted squared
      distance to the quantile and labels it in the ensemble. Also indicates which realizations
      correspond to the selected quantiles.

   :param ens: DataFrame read from an observation
   :type ens: pandas DataFrame
   :param pst:
   :type pst: pyemy.Pst object
   :param quantiles: quantiles ranging from 0-1.0 for which results requested
   :type quantiles: iterable
   :param subset_obsnames: list of observation names to include in calculations
   :type subset_obsnames: iterable
   :param subset_obsgroups: list of observation groups to include in calculations
   :type subset_obsgroups: iterable

   :returns:

             same ens object that was input but with quantile realizations
                                 appended as new rows labelled with 'q_#' where '#' is the slected quantile
             quantile_idx (dictionary): dictionary with keys being quantiles and values being realizations
                                     corresponding to each realization
   :rtype: ens (pandas DataFrame)


.. function:: calc_rmse_ensemble(ens, pst, bygroups=True, subset_realizations=None)

   Calculates RMSE (without weights) to quantify fit to observations for ensemble members

   :param ens: DataFrame read from an observation
   :type ens: pandas DataFrame
   :param pst:
   :type pst: pyemy.Pst object
   :param bygroups: Flag to summarize by groups or not. Defaults to True.
   :type bygroups: Bool
   :param subset_realizations: Subset of realizations for which
                               to report RMSE. Defaults to None which returns all realizations.
   :type subset_realizations: iterable, optional

   :returns: rows are realizations. Columns are groups. Content is RMSE
   :rtype: rmse (pandas DataFrame object)


.. function:: _condition_on_par_knowledge(cov, par_knowledge_dict)

   experimental function to include conditional prior information
   for one or more parameters in a full covariance matrix


.. function:: kl_setup(num_eig, sr, struct, prefixes, factors_file='kl_factors.dat', islog=True, basis_file=None, tpl_dir='.')

   setup a karhuenen-Loeve based parameterization for a given
   geostatistical structure.

   :param num_eig: the number of basis vectors to retain in the
                   reduced basis
   :type num_eig: `int`
   :param sr: a spatial reference instance
   :type sr: `flopy.reference.SpatialReference`
   :param struct: a PEST-style structure file.  Can also be a
                  `pyemu.geostats.Geostruct` instance.
   :type struct: `str`
   :param prefixes: a list of parameter prefixes to generate KL
                    parameterization for.
   :type prefixes: [`str`]
   :param factors_file: name of the PEST-style interpolation
                        factors file to write (can be processed with FAC2REAL).
                        Default is "kl_factors.dat".
   :type factors_file: `str`, optional
   :param islog: flag to indicate if the parameters are log transformed.
                 Default is True
   :type islog: `bool`, optional
   :param basis_file: the name of the PEST-style binary (e.g. jco)
                      file to write the reduced basis vectors to.  Default is None (not saved).
   :type basis_file: `str`, optional
   :param tpl_dir: the directory to write the resulting
                   template files to.  Default is "." (current directory).
   :type tpl_dir: `str`, optional

   :returns: a dataframe of parameter information.
   :rtype: `pandas.DataFrame`

   .. note:: This is the companion function to `helpers.apply_kl()`

   Example::

       m = flopy.modflow.Modflow.load("mymodel.nam")
       prefixes = ["hk","vka","ss"]
       df = pyemu.helpers.kl_setup(10,m.sr,"struct.dat",prefixes)


.. function:: _eigen_basis_to_factor_file(nrow, ncol, basis, factors_file, islog=True)


.. function:: kl_apply(par_file, basis_file, par_to_file_dict, arr_shape)

   Apply a KL parameterization transform from basis factors to model
   input arrays.

   :param par_file: the csv file to get factor values from.  Must contain
                    the following columns: "name", "new_val", "org_val"
   :type par_file: `str`
   :param basis_file: the PEST-style binary file that contains the reduced
                      basis
   :type basis_file: `str`
   :param par_to_file_dict: a mapping from KL parameter prefixes to array
                            file names.
   :type par_to_file_dict: `dict`
   :param arr_shape: a length 2 tuple of number of rows and columns
                     the resulting arrays should have.
   :type arr_shape: tuple
   :param Note: This is the companion function to kl_setup.
                This function should be called during the forward run


.. function:: zero_order_tikhonov(pst, parbounds=True, par_groups=None, reset=True)

   setup preferred-value regularization in a pest control file.

   :param pst: the control file instance
   :type pst: `pyemu.Pst`
   :param parbounds: flag to weight the new prior information
                     equations according to parameter bound width - approx the KL
                     transform. Default is True
   :type parbounds: `bool`, optional
   :param par_groups: a list of parameter groups to build PI equations for.
                      If None, all adjustable parameters are used. Default is None
   :type par_groups: `list`
   :param reset: a flag to remove any existing prior information equations
                 in the control file.  Default is True
   :type reset: `bool`

   Example::

       pst = pyemu.Pst("my.pst")
       pyemu.helpers.zero_order_tikhonov(pst)
       pst.write("my_reg.pst")


.. function:: _regweight_from_parbound(pst)

   sets regularization weights from parameter bounds
   which approximates the KL expansion.  Called by
   zero_order_tikhonov().


.. function:: first_order_pearson_tikhonov(pst, cov, reset=True, abs_drop_tol=0.001)

   setup preferred-difference regularization from a covariance matrix.


   :param pst: the PEST control file
   :type pst: `pyemu.Pst`
   :param cov: a covariance matrix instance with
               some or all of the parameters listed in `pst`.
   :type cov: `pyemu.Cov`
   :param reset: a flag to remove any existing prior information equations
                 in the control file.  Default is True
   :type reset: `bool`
   :param abs_drop_tol: tolerance to control how many pi equations
                        are written. If the absolute value of the Pearson CC is less than
                        abs_drop_tol, the prior information equation will not be included in
                        the control file.
   :type abs_drop_tol: `float`, optional

   .. note::

      The weights on the prior information equations are the Pearson
      correlation coefficients implied by covariance matrix.

   Example::

       pst = pyemu.Pst("my.pst")
       cov = pyemu.Cov.from_ascii("my.cov")
       pyemu.helpers.first_order_pearson_tikhonov(pst,cov)
       pst.write("my_reg.pst")


.. function:: simple_tpl_from_pars(parnames, tplfilename='model.input.tpl')

   Make a simple template file from a list of parameter names.

   :param parnames: list of parameter names to put in the
                    new template file
   :type parnames: [`str`]
   :param tplfilename: Name of the template file to create.  Default
                       is "model.input.tpl"
   :type tplfilename: `str`

   .. note:: writes a file `tplfilename` with each parameter name in `parnames` on a line


.. function:: simple_ins_from_obs(obsnames, insfilename='model.output.ins')

   write a simple instruction file that reads the values named
    in obsnames in order, one per line from a model output file

   :param obsnames: list of observation names to put in the
                    new instruction file
   :type obsnames: `str`
   :param insfilename: the name of the instruction file to
                       create. Default is "model.output.ins"
   :type insfilename: `str`

   .. note::

      writes a file `insfilename` with each observation read off
      of a single line


.. function:: pst_from_parnames_obsnames(parnames, obsnames, tplfilename='model.input.tpl', insfilename='model.output.ins')

   Creates a Pst object from a list of parameter names and a list of observation names.

   :param parnames: list of parameter names
   :type parnames: `str`
   :param obsnames: list of observation names
   :type obsnames: `str`
   :param tplfilename: template filename. Default is  "model.input.tpl"
   :type tplfilename: `str`
   :param insfilename: instruction filename. Default is "model.output.ins"
   :type insfilename: `str`

   :returns: the generic control file
   :rtype: `pyemu.Pst`


.. function:: read_pestpp_runstorage(filename, irun=0, with_metadata=False)

   read pars and obs from a specific run in a pest++ serialized
   run storage file into dataframes.

   :param filename: the name of the run storage file
   :type filename: `str`
   :param irun: the run id to process. If 'all', then all runs are
                read. Default is 0
   :type irun: `int`
   :param with_metadata: flag to return run stats and info txt as well
   :type with_metadata: `bool`

   :returns: tuple containing

             - **pandas.DataFrame**: parameter information
             - **pandas.DataFrame**: observation information
             - **pandas.DataFrame**: optionally run status and info txt.


.. function:: jco_from_pestpp_runstorage(rnj_filename, pst_filename)

   read pars and obs from a pest++ serialized run storage
   file (e.g., .rnj) and return jacobian matrix instance

   :param rnj_filename: the name of the run storage file
   :type rnj_filename: `str`
   :param pst_filename: the name of the pst file
   :type pst_filename: `str`

   .. note::

      This can then be passed to Jco.to_binary or Jco.to_coo, etc., to write jco
      file in a subsequent step to avoid memory resource issues associated
      with very large problems.

   :returns: a jacobian matrix constructed from the run results and
             pest control file information.
   :rtype: `pyemu.Jco`


.. function:: parse_dir_for_io_files(d, prepend_path=False)

   find template/input file pairs and instruction file/output file
   pairs by extension.

   :param d: directory to search for interface files
   :type d: `str`
   :param prepend_path: flag to prepend `d` to each file name.
                        Default is False
   :type prepend_path: `bool`, optional

   .. note::

      the return values from this function can be passed straight to
      `pyemu.Pst.from_io_files()` classmethod constructor. Assumes the
      template file names are <input_file>.tpl and instruction file names
      are <output_file>.ins.

   :returns: tuple containing

             - **[`str`]**: list of template files in d
             - **[`str`]**: list of input files in d
             - **[`str`]**: list of instruction files in d
             - **[`str`]**: list of output files in d


.. function:: pst_from_io_files(tpl_files, in_files, ins_files, out_files, pst_filename=None, pst_path=None)

   create a Pst instance from model interface files.

   :param tpl_files: list of template file names
   :type tpl_files: [`str`]
   :param in_files: list of model input file names (pairs with template files)
   :type in_files: [`str`]
   :param ins_files: list of instruction file names
   :type ins_files: [`str`]
   :param out_files: list of model output file names (pairs with instruction files)
   :type out_files: [`str`]
   :param pst_filename: name of control file to write.  If None, no file is written.
                        Default is None
   :type pst_filename: `str`
   :param pst_path: the path to append to the template_file and in_file in the control file.  If
                    not None, then any existing path in front of the template or in file is split off
                    and pst_path is prepended.  If python is being run in a directory other than where the control
                    file will reside, it is useful to pass `pst_path` as `.`.  Default is None
   :type pst_path: `str`

   :returns: new control file instance with parameter and observation names
             found in `tpl_files` and `ins_files`, repsectively.
   :rtype: `Pst`

   .. note::

      calls `pyemu.helpers.pst_from_io_files()`
      
      Assigns generic values for parameter info.  Tries to use INSCHEK
      to set somewhat meaningful observation values
      
      all file paths are relatively to where python is running.

   Example::

       tpl_files = ["my.tpl"]
       in_files = ["my.in"]
       ins_files = ["my.ins"]
       out_files = ["my.out"]
       pst = pyemu.Pst.from_io_files(tpl_files,in_files,ins_files,out_files)
       pst.control_data.noptmax = 0
       pst.write("my.pst)




.. data:: wildass_guess_par_bounds_dict
   

   

.. py:class:: PstFromFlopyModel(model, new_model_ws, org_model_ws=None, pp_props=[], const_props=[], temporal_bc_props=[], temporal_list_props=[], grid_props=[], grid_geostruct=None, pp_space=None, zone_props=[], pp_geostruct=None, par_bounds_dict=None, sfr_pars=False, temporal_sfr_pars=False, temporal_list_geostruct=None, remove_existing=False, k_zone_dict=None, mflist_waterbudget=True, mfhyd=True, hds_kperk=[], use_pp_zones=False, obssim_smp_pairs=None, external_tpl_in_pairs=None, external_ins_out_pairs=None, extra_pre_cmds=None, extra_model_cmds=None, extra_post_cmds=None, redirect_forward_output=True, tmp_files=None, model_exe_name=None, build_prior=True, sfr_obs=False, spatial_bc_props=[], spatial_list_props=[], spatial_list_geostruct=None, hfb_pars=False, kl_props=None, kl_num_eig=100, kl_geostruct=None)

   Bases: :class:`object`

   a monster helper class to setup a complex PEST interface around
   an existing MODFLOW-2005-family model.


   :param model: a loaded flopy model instance. If model is an str, it is treated as a
                 MODFLOW nam file (requires org_model_ws)
   :type model: `flopy.mbase`
   :param new_model_ws: a directory where the new version of MODFLOW input files and PEST(++)
                        files will be written
   :type new_model_ws: `str`
   :param org_model_ws: directory to existing MODFLOW model files.  Required if model argument
                        is an str.  Default is None
   :type org_model_ws: `str`
   :param pp_props: pilot point multiplier parameters for grid-based properties.
                    A nested list of grid-scale model properties to parameterize using
                    name, iterable pairs.  For 3D properties, the iterable is zero-based
                    layer indices.  For example, ["lpf.hk",[0,1,2,]] would setup pilot point multiplier
                    parameters for layer property file horizontal hydraulic conductivity for model
                    layers 1,2, and 3.  For time-varying properties (e.g. recharge), the
                    iterable is for zero-based stress period indices.  For example, ["rch.rech",[0,4,10,15]]
                    would setup pilot point multiplier parameters for recharge for stress
                    period 1,5,11,and 16.
   :type pp_props: [[`str`,[`int`]]]
   :param const_props: constant (uniform) multiplier parameters for grid-based properties.
                       A nested list of grid-scale model properties to parameterize using
                       name, iterable pairs.  For 3D properties, the iterable is zero-based
                       layer indices.  For example, ["lpf.hk",[0,1,2,]] would setup constant (uniform) multiplier
                       parameters for layer property file horizontal hydraulic conductivity for model
                       layers 1,2, and 3.  For time-varying properties (e.g. recharge), the
                       iterable is for zero-based stress period indices.  For example, ["rch.rech",[0,4,10,15]]
                       would setup constant (uniform) multiplier parameters for recharge for stress
                       period 1,5,11,and 16.
   :type const_props: [[`str`,[`int`]]]
   :param temporal_list_props: list-type input stress-period level multiplier parameters.
                               A nested list of list-type input elements to parameterize using
                               name, iterable pairs.  The iterable is zero-based stress-period indices.
                               For example, to setup multipliers for WEL flux and for RIV conductance,
                               temporal_list_props = [["wel.flux",[0,1,2]],["riv.cond",None]] would setup
                               multiplier parameters for well flux for stress periods 1,2 and 3 and
                               would setup one single river conductance multiplier parameter that is applied
                               to all stress periods
   :type temporal_list_props: [[`str`,[`int`]]]
   :param spatial_list_props: list-type input for spatial multiplier parameters.
                              A nested list of list-type elements to parameterize using
                              names (e.g. [["riv.cond",0],["wel.flux",1] to setup up cell-based parameters for
                              each list-type element listed.  These multiplier parameters are applied across
                              all stress periods.  For this to work, there must be the same number of entries
                              for all stress periods.  If more than one list element of the same type is in a single
                              cell, only one parameter is used to multiply all lists in the same cell.
   :type spatial_list_props: [[`str`,[`int`]]]
   :param grid_props: grid-based (every active model cell) multiplier parameters.
                      A nested list of grid-scale model properties to parameterize using
                      name, iterable pairs.  For 3D properties, the iterable is zero-based
                      layer indices (e.g., ["lpf.hk",[0,1,2,]] would setup a multiplier
                      parameter for layer property file horizontal hydraulic conductivity for model
                      layers 1,2, and 3 in every active model cell).  For time-varying properties (e.g. recharge), the
                      iterable is for zero-based stress period indices.  For example, ["rch.rech",[0,4,10,15]]
                      would setup grid-based multiplier parameters in every active model cell
                      for recharge for stress period 1,5,11,and 16.
   :type grid_props: [[`str`,[`int`]]]
   :param sfr_pars: setup parameters for the stream flow routing modflow package.
                    If list is passed it defines the parameters to set up.
   :type sfr_pars: `bool`
   :param sfr_temporal_pars: flag to include stress-period level spatially-global multipler parameters in addition to
                             the spatially-discrete `sfr_pars`.  Requires `sfr_pars` to be passed.  Default is False
   :type sfr_temporal_pars: `bool`
   :param grid_geostruct: the geostatistical structure to build the prior parameter covariance matrix
                          elements for grid-based parameters.  If None, a generic GeoStruct is created
                          using an "a" parameter that is 10 times the max cell size.  Default is None
   :type grid_geostruct: `pyemu.geostats.GeoStruct`
   :param pp_space: number of grid cells between pilot points.  If None, use the default
                    in pyemu.pp_utils.setup_pilot_points_grid.  Default is None
   :type pp_space: `int`
   :param zone_props: zone-based multiplier parameters.
                      A nested list of zone-based model properties to parameterize using
                      name, iterable pairs.  For 3D properties, the iterable is zero-based
                      layer indices (e.g., ["lpf.hk",[0,1,2,]] would setup a multiplier
                      parameter for layer property file horizontal hydraulic conductivity for model
                      layers 1,2, and 3 for unique zone values in the ibound array.
                      For time-varying properties (e.g. recharge), the iterable is for
                      zero-based stress period indices.  For example, ["rch.rech",[0,4,10,15]]
                      would setup zone-based multiplier parameters for recharge for stress
                      period 1,5,11,and 16.
   :type zone_props: [[`str`,[`int`]]]
   :param pp_geostruct: the geostatistical structure to use for building the prior parameter
                        covariance matrix for pilot point parameters.  If None, a generic
                        GeoStruct is created using pp_space and grid-spacing information.
                        Default is None
   :type pp_geostruct: `pyemu.geostats.GeoStruct`
   :param par_bounds_dict: a dictionary of model property/boundary condition name, upper-lower bound pairs.
                           For example, par_bounds_dict = {"hk":[0.01,100.0],"flux":[0.5,2.0]} would
                           set the bounds for horizontal hydraulic conductivity to
                           0.001 and 100.0 and set the bounds for flux parameters to 0.5 and
                           2.0.  For parameters not found in par_bounds_dict,
                           `pyemu.helpers.wildass_guess_par_bounds_dict` is
                           used to set somewhat meaningful bounds.  Default is None
   :type par_bounds_dict: `dict`
   :param temporal_list_geostruct: the geostastical struture to
                                   build the prior parameter covariance matrix
                                   for time-varying list-type multiplier parameters.  This GeoStruct
                                   express the time correlation so that the 'a' parameter is the length of
                                   time that boundary condition multiplier parameters are correlated across.
                                   If None, then a generic GeoStruct is created that uses an 'a' parameter
                                   of 3 stress periods.  Default is None
   :type temporal_list_geostruct: `pyemu.geostats.GeoStruct`
   :param spatial_list_geostruct: the geostastical struture to
                                  build the prior parameter covariance matrix
                                  for spatially-varying list-type multiplier parameters.
                                  If None, a generic GeoStruct is created using an "a" parameter that
                                  is 10 times the max cell size.  Default is None.
   :type spatial_list_geostruct: `pyemu.geostats.GeoStruct`
   :param remove_existing: a flag to remove an existing new_model_ws directory.  If False and
                           new_model_ws exists, an exception is raised.  If True and new_model_ws
                           exists, the directory is destroyed - user beware! Default is False.
   :type remove_existing: `bool`
   :param k_zone_dict: a dictionary of zero-based layer index, zone array pairs.
                       e.g. {lay: np.2darray}  Used to
                       override using ibound zones for zone-based parameterization.  If None,
                       use ibound values greater than zero as zones. Alternatively a dictionary of dictionaries
                       can be passed to allow different zones to be defined for different parameters.
                       e.g. {"upw.hk" {lay: np.2darray}, "extra.rc11" {lay: np.2darray}}
                       or {"hk" {lay: np.2darray}, "rc11" {lay: np.2darray}}
   :type k_zone_dict: `dict`
   :param use_pp_zones: a flag to use ibound zones (or k_zone_dict, see above) as pilot
                        point zones.  If False, ibound values greater than zero are treated as
                        a single zone for pilot points.  Default is False
   :type use_pp_zones: `bool`
   :param obssim_smp_pairs ([[`str`: a list of observed-simulated PEST-type SMP file
                                     pairs to get observations
                                     from and include in the control file.  Default is []
   :param `str`]]: a list of observed-simulated PEST-type SMP file
                   pairs to get observations
                   from and include in the control file.  Default is []
   :param external_tpl_in_pairs ([[`str`: a list of existing template file, model input
                                          file pairs to parse parameters
                                          from and include in the control file.  Default is []
   :param `str`]]: a list of existing template file, model input
                   file pairs to parse parameters
                   from and include in the control file.  Default is []
   :param external_ins_out_pairs ([[`str`: a list of existing instruction file,
                                           model output file pairs to parse
                                           observations from and include in the control file.  Default is []
   :param `str`]]: a list of existing instruction file,
                   model output file pairs to parse
                   observations from and include in the control file.  Default is []
   :param extra_pre_cmds: a list of preprocessing commands to add to the forward_run.py script
                          commands are executed with os.system() within forward_run.py. Default is None.
   :type extra_pre_cmds: [`str`]
   :param redirect_forward_output: flag for whether to redirect forward model output to text files (True) or
                                   allow model output to be directed to the screen (False).  Default is True
   :type redirect_forward_output: `bool`
   :param extra_post_cmds: a list of post-processing commands to add to the forward_run.py script.
                           Commands are executed with os.system() within forward_run.py. Default is None.
   :type extra_post_cmds: [`str`]
   :param tmp_files: a list of temporary files that should be removed at the start of the forward
                     run script.  Default is [].
   :type tmp_files: [`str`]
   :param model_exe_name: binary name to run modflow.  If None, a default from flopy is used,
                          which is dangerous because of the non-standard binary names
                          (e.g. MODFLOW-NWT_x64, MODFLOWNWT, mfnwt, etc). Default is None.
   :type model_exe_name: `str`
   :param build_prior: flag to build prior covariance matrix. Default is True
   :type build_prior: `bool`
   :param sfr_obs: flag to include observations of flow and aquifer exchange from
                   the sfr ASCII output file
   :type sfr_obs: `bool`
   :param hfb_pars: add HFB parameters.  uses pyemu.gw_utils.write_hfb_template().  the resulting
                    HFB pars have parval1 equal to the values in the original file and use the
                    spatial_list_geostruct to build geostatistical covariates between parameters
   :type hfb_pars: `bool`
   :param kl_props: karhunen-loeve based multiplier parameters.
                    A nested list of KL-based model properties to parameterize using
                    name, iterable pairs.  For 3D properties, the iterable is zero-based
                    layer indices (e.g., ["lpf.hk",[0,1,2,]] would setup a multiplier
                    parameter for layer property file horizontal hydraulic conductivity for model
                    layers 1,2, and 3 for unique zone values in the ibound array.
                    For time-varying properties (e.g. recharge), the iterable is for
                    zero-based stress period indices.  For example, ["rch.rech",[0,4,10,15]]
                    would setup zone-based multiplier parameters for recharge for stress
                    period 1,5,11,and 16.
   :type kl_props: [[`str`,[`int`]]]
   :param kl_num_eig: the number of KL-based eigenvector multiplier parameters to use for each
                      KL parameter set. default is 100
   :type kl_num_eig: `int`
   :param kl_geostruct: the geostatistical structure
                        to build the prior parameter covariance matrix
                        elements for KL-based parameters.  If None, a generic GeoStruct is created
                        using an "a" parameter that is 10 times the max cell size.  Default is None
   :type kl_geostruct: `pyemu.geostats.Geostruct`

   .. note::

      Setup up multiplier parameters for an existing MODFLOW model.
      
      Does all kinds of coolness like building a
      meaningful prior, assigning somewhat meaningful parameter groups and
      bounds, writes a forward_run.py script with all the calls need to
      implement multiplier parameters, run MODFLOW and post-process.
      
      Works a lot better if TEMPCHEK, INSCHEK and PESTCHEK are available in the
      system path variable

   .. method:: _setup_sfr_obs(self)

      setup sfr ASCII observations


   .. method:: _setup_sfr_pars(self, par_cols=None, include_temporal_pars=None)

      setup multiplier parameters for sfr segment data
      Adding support for reachinput (and isfropt = 1)


   .. method:: _setup_hfb_pars(self)

      setup non-mult parameters for hfb (yuck!)



   .. method:: _setup_mult_dirs(self)

      setup the directories to use for multiplier parameterization.  Directories
      are make within the PstFromFlopyModel.m.model_ws directory


   .. method:: _setup_model(self, model, org_model_ws, new_model_ws)

      setup the flopy.mbase instance for use with multipler parameters.
      Changes model_ws, sets external_path and writes new MODFLOW input
      files


   .. method:: _get_count(self, name)

      get the latest counter for a certain parameter type.



   .. method:: _prep_mlt_arrays(self)

      prepare multipler arrays.  Copies existing model input arrays and
      writes generic (ones) multiplier arrays


   .. method:: _write_u2d(self, u2d)

      write a flopy.utils.Util2D instance to an ASCII text file using the
      Util2D filename


   .. method:: _write_const_tpl(self, name, tpl_file, zn_array)

      write a template file a for a constant (uniform) multiplier parameter



   .. method:: _write_grid_tpl(self, name, tpl_file, zn_array)

      write a template file a for grid-based multiplier parameters



   .. method:: _grid_prep(self)

      prepare grid-based parameterizations



   .. method:: _pp_prep(self, mlt_df)

      prepare pilot point based parameterization




   .. method:: _kl_prep(self, mlt_df)

      prepare KL based parameterizations



   .. method:: _setup_array_pars(self)

      main entry point for setting up array multipler parameters



   .. method:: _setup_observations(self)

      main entry point for setting up observations



   .. method:: draw(self, num_reals=100, sigma_range=6, use_specsim=False, scale_offset=True)

      draw from the geostatistically-implied parameter covariance matrix

      :param num_reals: number of realizations to generate. Default is 100
      :type num_reals: `int`
      :param sigma_range: number of standard deviations represented by
                          the parameter bounds.  Default is 6.
      :type sigma_range: `float`
      :param use_specsim: flag to use spectral simulation for grid-based
                          parameters.  Requires a regular grid but is wicked fast.  Default is False
      :type use_specsim: `bool`
      :param scale_offset: flag to apply scale and offset to parameter
                           bounds when calculating variances - this is passed through to
                           `pyemu.Cov.from_parameter_data`.  Default is True.
      :type scale_offset: `bool`, optional

      .. note::

         operates on parameters by groups to avoid having to construct a very large
         covariance matrix for problems with more the 30K parameters.
         
         uses `helpers.geostatitical_draw()`

      :returns: The realized parameter ensemble
      :rtype: `pyemu.ParameterEnsemble`


   .. method:: build_prior(self, fmt='ascii', filename=None, droptol=None, chunk=None, sigma_range=6)

      build and optionally save the prior parameter covariance matrix.

      :param fmt: the format to save the cov matrix.  Options are "ascii","binary","uncfile", "coo".
                  Default is "ascii".  If "none" (lower case string, not None), then no file is created.
      :type fmt: `str`, optional
      :param filename: the filename to save the prior cov matrix to.  If None, the name is formed using
                       model nam_file name.  Default is None.
      :type filename: `str`, optional
      :param droptol: tolerance for dropping near-zero values when writing compressed binary.
                      Default is None.
      :type droptol: `float`, optional
      :param chunk: chunk size to write in a single pass - for binary only.  Default
                    is None (no chunking).
      :type chunk: `int`, optional
      :param sigma_range: number of standard deviations represented by the parameter bounds.  Default
                          is 6.
      :type sigma_range: `float`

      :returns: the full prior parameter covariance matrix, generated by processing parameters by
                groups
      :rtype: `pyemu.Cov`


   .. method:: build_pst(self, filename=None)

      build the pest control file using the parameters and
      observations.

      :param filename: the filename to save the contorl file to.  If None, the
                       name if formed from the model namfile name.  Default is None.  The control
                       is saved in the `PstFromFlopy.m.model_ws` directory.
      :type filename: `str`

      .. note::

         calls pyemu.Pst.from_io_files
         
         calls PESTCHEK


   .. method:: _add_external(self)

      add external (existing) template files and/or instruction files to the
      Pst instance


   .. method:: write_forward_run(self)

      write the forward run script forward_run.py

      .. note::

         This method can be called repeatedly, especially after any
         changed to the pre- and/or post-processing routines.


   .. method:: _parse_k(self, k, vals)

      parse the iterable from a property or boundary condition argument


   .. method:: _parse_pakattr(self, pakattr)

      parse package-iterable pairs from a property or boundary condition
      argument


   .. method:: _setup_list_pars(self)

      main entry point for setting up list multiplier
      parameters


   .. method:: _setup_temporal_list_pars(self)


   .. method:: _setup_spatial_list_pars(self)


   .. method:: _list_helper(self, k, pak, attr, col)

      helper to setup list multiplier parameters for a given
      k, pak, attr set.


   .. method:: _setup_hds(self)

      setup modflow head save file observations for given kper (zero-based
      stress period index) and k (zero-based layer index) pairs using the
      kperk argument.


   .. method:: _setup_smp(self)

      setup observations from PEST-style SMP file pairs



   .. method:: _setup_hob(self)

      setup observations from the MODFLOW HOB package


   .. method:: _setup_hyd(self)

      setup observations from the MODFLOW HYDMOD package


   .. method:: _setup_water_budget_obs(self)

      setup observations from the MODFLOW list file for
      volume and flux water buget information



.. function:: apply_list_and_array_pars(arr_par_file='mult2model_info.csv', chunk_len=50)

   Apply multiplier parameters to list and array style model files

   :param arr_par_file:
   :type arr_par_file: str
   :param chunk_len: the number of files to process per multiprocessing
                     chunk in appl_array_pars().  default is 50.
   :type chunk_len: `int`

   Returns:

   .. note::

      Used to implement the parameterization constructed by
      PstFrom during a forward run
      
      Should be added to the forward_run.py script


.. function:: _process_chunk_fac2real(chunk, i)


.. function:: _process_chunk_model_files(chunk, i, df)


.. function:: _process_model_file(model_file, df)


.. function:: apply_array_pars(arr_par='arr_pars.csv', arr_par_file=None, chunk_len=50)

   a function to apply array-based multipler parameters.

   :param arr_par: if type `str`,
   :type arr_par: `str` or `pandas.DataFrame`
   :param path to csv file detailing parameter array multipliers.: This file can be written by PstFromFlopy.
   :param if type `pandas.DataFrame` is Dataframe with columns of:
   :param ['mlt_file':
   :param 'model_file':
   :param 'org_file'] and optionally:
   :param ['pp_file':
   :param 'fac_file'].:
   :param chunk_len: the number of files to process per chunk
                     with multiprocessing - applies to both fac2real and process_
                     input_files. Default is 50.
   :type chunk_len: `int`

   .. note::

      Used to implement the parameterization constructed by
      PstFromFlopyModel during a forward run
      
      This function should be added to the forward_run.py script but can
      be called on any correctly formatted csv
      
      This function using multiprocessing, spawning one process for each
      model input array (and optionally pp files).  This speeds up
      execution time considerably but means you need to make sure your
      forward run script uses the proper multiprocessing idioms for
      freeze support and main thread handling.


.. function:: apply_list_pars()

   a function to apply boundary condition multiplier parameters.

   .. note::

      Used to implement the parameterization constructed by
      PstFromFlopyModel during a forward run
      
      Requires either "temporal_list_pars.csv" or "spatial_list_pars.csv"
      
      Should be added to the forward_run.py script


.. function:: apply_genericlist_pars(df)

   a function to apply list style mult parameters

   :param df: DataFrame that relates files containing
              multipliers to model input file names. Required columns include:
              {"model_file": file name of resulatant model input file,
              "org_file": file name of original file that multipliers act on,
              "fmt": format specifier for model input file (currently on 'free' supported),
              "sep": separator for model input file if 'free' formatted,
              "head_rows": Number of header rows to transfer from orig file to model file,
              "index_cols": list of columns (either indexes or strings) to be used to align mults, orig and model files,
              "use_cols": columns to mults act on,
              "upper_bound": ultimate upper bound for model input file parameter,
              "lower_bound": ultimate lower bound for model input file parameter}
   :type df: pandas.DataFrame


.. function:: write_const_tpl(name, tpl_file, suffix, zn_array=None, shape=None, longnames=False)

   write a constant (uniform) template file for a 2-D array

   :param name: the base parameter name
   :type name: `str`
   :param tpl_file: the template file to write
   :type tpl_file: `str`
   :param zn_array: an array used to skip inactive cells,
                    and optionally get shape info.
   :type zn_array: `numpy.ndarray`, optional
   :param shape: tuple nrow and ncol.  Either `zn_array` or `shape`
                 must be passed
   :type shape: `tuple`
   :param longnames: flag to use longer names that exceed 12 chars in length.
                     Default is False.
   :type longnames: `bool`

   :returns: a dataframe with parameter information
   :rtype: `pandas.DataFrame`


.. function:: write_grid_tpl(name, tpl_file, suffix, zn_array=None, shape=None, spatial_reference=None, longnames=False)

   write a grid-based template file for a 2-D array

   :param name: the base parameter name
   :type name: `str`
   :param tpl_file: the template file to write - include path
   :type tpl_file: `str`
   :param zn_array: zone array to identify
                    inactive cells.  Default is None
   :type zn_array: `numpy.ndarray`, optional
   :param shape: a length-two tuple of nrow and ncol.  Either
                 `zn_array` or `shape` must be passed.
   :type shape: `tuple`, optional
   :param spatial_reference: a spatial reference instance.
                             If `longnames` is True, then `spatial_reference` is used to add spatial info
                             to the parameter names.
   :type spatial_reference: `flopy.utils.SpatialReference`
   :param longnames: flag to use longer names that exceed 12 chars in length.
                     Default is False.
   :type longnames: `bool`

   :returns: a dataframe with parameter information
   :rtype: `pandas.DataFrame`


.. function:: write_zone_tpl(name, tpl_file, suffix='', zn_array=None, shape=None, longnames=False, fill_value='1.0')

   write a zone-based template file for a 2-D array

   :param name: the base parameter name
   :type name: `str`
   :param tpl_file: the template file to write
   :type tpl_file: `str`
   :param suffix: suffix to add to parameter names.  Only used if `longnames=True`
   :type suffix: `str`
   :param zn_array: an array used to skip inactive cells,
                    and optionally get shape info.  zn_array values less than 1 are given `fill_value`
   :type zn_array: `numpy.ndarray`, optional
   :param shape: tuple nrow and ncol.  Either `zn_array` or `shape`
                 must be passed
   :type shape: `tuple`
   :param longnames: flag to use longer names that exceed 12 chars in length.
                     Default is False.
   :type longnames: `bool`
   :param fill_value: value to fill locations where `zn_array` is less than 1.0.
                      Default is "1.0".
   :type fill_value: `str`

   :returns: a dataframe with parameter information
   :rtype: `pandas.DataFrame`


.. function:: build_jac_test_csv(pst, num_steps, par_names=None, forward=True)

   build a dataframe of jactest inputs for use with sweep

   :param pst: existing control file
   :type pst: `pyemu.Pst`
   :param num_steps: number of pertubation steps for each parameter
   :type num_steps: `int`
   :param par_names [`str`]: list of parameter names of pars to test.
                             If None, all adjustable pars are used. Default is None
   :param forward: flag to start with forward pertubations.
                   Default is True
   :type forward: `bool`

   :returns: the sequence of model runs to evaluate
             for the jactesting.
   :rtype: `pandas.DataFrame`


.. function:: _write_df_tpl(filename, df, sep=',', tpl_marker='~', **kwargs)

   function write a pandas dataframe to a template file.



.. function:: setup_fake_forward_run(pst, new_pst_name, org_cwd='.', bak_suffix='._bak', new_cwd='.')

   setup a fake forward run for a pst.

   :param pst: existing control file
   :type pst: `pyemu.Pst`
   :param new_pst_name: new control file to write
   :type new_pst_name: `str`
   :param org_cwd: existing working dir.  Default is "."
   :type org_cwd: `str`
   :param bak_suffix: suffix to add to existing
                      model output files when making backup copies.
   :type bak_suffix: `str`, optional
   :param new_cwd: new working dir.  Default is ".".
   :type new_cwd: `str`

   .. note::

      The fake forward run simply copies existing backup versions of
      model output files to the outfiles pest(pp) is looking
      for.  This is really a development option for debugging
      PEST++ issues.


.. function:: setup_temporal_diff_obs(pst, ins_file, out_file=None, include_zero_weight=False, include_path=False, sort_by_name=True, long_names=True, prefix='dif')

   a helper function to setup difference-in-time observations based on an existing
   set of observations in an instruction file using the observation grouping in the
   control file

   :param pst: existing control file
   :type pst: `pyemu.Pst`
   :param ins_file: an existing instruction file
   :type ins_file: `str`
   :param out_file: an existing model output file that corresponds to
                    the instruction file.  If None, `ins_file.replace(".ins","")` is used
   :type out_file: `str`, optional
   :param include_zero_weight: flag to include zero-weighted observations
                               in the difference observation process.  Default is False so that only non-zero
                               weighted observations are used.
   :type include_zero_weight: `bool`, optional
   :param include_path: flag to setup the binary file processing in directory where the hds_file
                        is located (if different from where python is running).  This is useful for setting up
                        the process in separate directory for where python is running.
   :type include_path: `bool`, optional
   :param sort_by_name: flag to sort observation names in each group prior to setting up
                        the differencing.  The order of the observations matters for the differencing.  If False, then
                        the control file order is used.  If observation names have a datetime suffix, make sure the format is
                        year-month-day to use this sorting.  Default is True
   :type sort_by_name: `bool`,optional
   :param long_names: flag to use long, descriptive names by concating the two observation names
                      that are being differenced.  This will produce names that are too long for tradtional PEST(_HP).
                      Default is True.
   :type long_names: `bool`, optional
   :param prefix: prefix to prepend to observation names and group names.  Default is "dif".
   :type prefix: `str`, optional

   :returns: tuple containing

             - **str**: the forward run command to execute the binary file process during model runs.

             - **pandas.DataFrame**: a dataframe of observation information for use in the pest control file

   .. note:: this is the companion function of `helpers.apply_temporal_diff_obs()`.


.. function:: apply_temporal_diff_obs(config_file)

   process an instruction-output file pair and formulate difference observations.

   :param config_file: configuration file written by `pyemu.helpers.setup_temporal_diff_obs`.
   :type config_file: `str`

   :returns: processed difference observations
   :rtype: diff_df (`pandas.DataFrame`)

   .. note::

      writes `config_file.replace(".config",".processed")` output file that can be read
      with the instruction file that is created by `pyemu.helpers.setup_temporal_diff_obs()`.
      
      this is the companion function of `helpers.setup_setup_temporal_diff_obs()`.


.. data:: srefhttp
   :annotation: = https://spatialreference.org

   

.. py:class:: SpatialReference(delr=np.array([]), delc=np.array([]), lenuni=2, xul=None, yul=None, xll=None, yll=None, rotation=0.0, proj4_str=None, epsg=None, prj=None, units=None, length_multiplier=None, source=None)

   Bases: :class:`object`

   a class to locate a structured model grid in x-y space.
   Lifted wholesale from Flopy, and preserved here...
   ...maybe slighlty over-engineered for here

   :param delr: the model discretization delr vector
                (An array of spacings along a row)
   :type delr: numpy ndarray
   :param delc: the model discretization delc vector
                (An array of spacings along a column)
   :type delc: numpy ndarray
   :param lenuni: the length units flag from the discretization package
                  (default 2)
   :type lenuni: int
   :param xul: the x coordinate of the upper left corner of the grid
               Enter either xul and yul or xll and yll.
   :type xul: float
   :param yul: the y coordinate of the upper left corner of the grid
               Enter either xul and yul or xll and yll.
   :type yul: float
   :param xll: the x coordinate of the lower left corner of the grid
               Enter either xul and yul or xll and yll.
   :type xll: float
   :param yll: the y coordinate of the lower left corner of the grid
               Enter either xul and yul or xll and yll.
   :type yll: float
   :param rotation: the counter-clockwise rotation (in degrees) of the grid
   :type rotation: float
   :param proj4_str: a PROJ4 string that identifies the grid in space. warning: case
                     sensitive!
   :type proj4_str: str
   :param units: Units for the grid.  Must be either feet or meters
   :type units: string
   :param epsg: EPSG code that identifies the grid in space. Can be used in lieu of
                proj4. PROJ4 attribute will auto-populate if there is an internet
                connection(via get_proj4 method).
                See https://www.epsg-registry.org/ or spatialreference.org
   :type epsg: int
   :param length_multiplier: multiplier to convert model units to spatial reference units.
                             delr and delc above will be multiplied by this value. (default=1.)
   :type length_multiplier: float

   .. attribute:: xedge

      array of column edges

      :type: ndarray

   .. attribute:: yedge

      array of row edges

      :type: ndarray

   .. attribute:: xgrid

      numpy meshgrid of xedges

      :type: ndarray

   .. attribute:: ygrid

      numpy meshgrid of yedges

      :type: ndarray

   .. attribute:: xcenter

      array of column centers

      :type: ndarray

   .. attribute:: ycenter

      array of row centers

      :type: ndarray

   .. attribute:: xcentergrid

      numpy meshgrid of column centers

      :type: ndarray

   .. attribute:: ycentergrid

      numpy meshgrid of row centers

      :type: ndarray

   .. attribute:: vertices

      1D array of cell vertices for whole grid in C-style (row-major) order
      (same as np.ravel())

      :type: 1D array

   .. rubric:: Notes

   xul and yul can be explicitly (re)set after SpatialReference
   instantiation, but only before any of the other attributes and methods are
   accessed

   .. attribute:: rotation
      :annotation: = 0.0

      

   .. attribute:: length_multiplier
      :annotation: = 1.0

      

   .. attribute:: origin_loc
      :annotation: = ul

      

   .. attribute:: defaults
      

      

   .. attribute:: lenuni_values
      

      

   .. attribute:: lenuni_text
      

      

   .. method:: xll(self)
      :property:


   .. method:: yll(self)
      :property:


   .. method:: xul(self)
      :property:


   .. method:: yul(self)
      :property:


   .. method:: proj4_str(self)
      :property:


   .. method:: epsg(self)
      :property:


   .. method:: lenuni(self)
      :property:


   .. method:: _parse_units_from_proj4(self)


   .. method:: units(self)
      :property:


   .. method:: length_multiplier(self)
      :property:

      Attempt to identify multiplier for converting from
      model units to sr units, defaulting to 1.


   .. method:: model_length_units(self)
      :property:


   .. method:: bounds(self)
      :property:

      Return bounding box in shapely order.


   .. method:: load(namefile=None, reffile='usgs.model.reference')
      :staticmethod:

      Attempts to load spatial reference information from
      the following files (in order):
      1) usgs.model.reference
      2) NAM file (header comment)
      3) SpatialReference.default dictionary


   .. method:: attribs_from_namfile_header(namefile)
      :staticmethod:


   .. method:: read_usgs_model_reference_file(reffile='usgs.model.reference')
      :staticmethod:

      read spatial reference info from the usgs.model.reference file
      https://water.usgs.gov/ogw/policy/gw-model/modelers-setup.html


   .. method:: __setattr__(self, key, value)

      Implement setattr(self, name, value).


   .. method:: reset(self, **kwargs)


   .. method:: _reset(self)


   .. method:: nrow(self)
      :property:


   .. method:: ncol(self)
      :property:


   .. method:: __eq__(self, other)

      Return self==value.


   .. method:: from_namfile(cls, namefile, delr=np.array([]), delc=np.array([]))
      :classmethod:


   .. method:: from_gridspec(cls, gridspec_file, lenuni=0)
      :classmethod:


   .. method:: attribute_dict(self)
      :property:


   .. method:: set_spatialreference(self, xul=None, yul=None, xll=None, yll=None, rotation=0.0)

      set spatial reference - can be called from model instance


   .. method:: __repr__(self)

      Return repr(self).


   .. method:: theta(self)
      :property:


   .. method:: xedge(self)
      :property:


   .. method:: yedge(self)
      :property:


   .. method:: xgrid(self)
      :property:


   .. method:: ygrid(self)
      :property:


   .. method:: xcenter(self)
      :property:


   .. method:: ycenter(self)
      :property:


   .. method:: ycentergrid(self)
      :property:


   .. method:: xcentergrid(self)
      :property:


   .. method:: _set_xycentergrid(self)


   .. method:: _set_xygrid(self)


   .. method:: rotate(x, y, theta, xorigin=0.0, yorigin=0.0)
      :staticmethod:

      Given x and y array-like values calculate the rotation about an
      arbitrary origin and then return the rotated coordinates.  theta is in
      degrees.


   .. method:: transform(self, x, y, inverse=False)

      Given x and y array-like values, apply rotation, scale and offset,
      to convert them from model coordinates to real-world coordinates.


   .. method:: get_extent(self)

      Get the extent of the rotated and offset grid

      Return (xmin, xmax, ymin, ymax)


   .. method:: get_grid_lines(self)

      Get the grid lines as a list


   .. method:: get_xcenter_array(self)

      Return a numpy one-dimensional float array that has the cell center x
      coordinate for every column in the grid in model space - not offset or rotated.


   .. method:: get_ycenter_array(self)

      Return a numpy one-dimensional float array that has the cell center x
      coordinate for every row in the grid in model space - not offset of rotated.


   .. method:: get_xedge_array(self)

      Return a numpy one-dimensional float array that has the cell edge x
      coordinates for every column in the grid in model space - not offset
      or rotated.  Array is of size (ncol + 1)


   .. method:: get_yedge_array(self)

      Return a numpy one-dimensional float array that has the cell edge y
      coordinates for every row in the grid in model space - not offset or
      rotated. Array is of size (nrow + 1)


   .. method:: write_gridspec(self, filename)

      write a PEST-style grid specification file


   .. method:: get_vertices(self, i, j)

      Get vertices for a single cell or sequence if i, j locations.


   .. method:: get_rc(self, x, y)


   .. method:: get_ij(self, x, y)

      Return the row and column of a point or sequence of points
      in real-world coordinates.

      :param x:
      :type x: scalar or sequence of x coordinates
      :param y:
      :type y: scalar or sequence of y coordinates

      :returns: * **i** (*row or sequence of rows (zero-based)*)
                * **j** (*column or sequence of columns (zero-based)*)


   .. method:: vertices(self)
      :property:

      Returns a list of vertices for


   .. method:: _set_vertices(self)

      Populate vertices for the whole grid



.. function:: get_maha_obs_summary(sim_en, l1_crit_val=6.34, l2_crit_val=9.2)

   calculate the 1-D and 2-D mahalanobis distance

   :param sim_en: a simulated outputs ensemble
   :type sim_en: `pyemu.ObservationEnsemble`
   :param l1_crit_val: the chi squared critical value for the 1-D
                       mahalanobis distance.  Default is 6.4 (p=0.01,df=1)
   :type l1_crit_val: `float`
   :param l2_crit_val: the chi squared critical value for the 2-D
                       mahalanobis distance.  Default is 9.2 (p=0.01,df=2)
   :type l2_crit_val: `float`

   :returns: tuple containing

             - **pandas.DataFrame**: 1-D subspace squared mahalanobis distances
                 that exceed the `l1_crit_val` threshold
             - **pandas.DataFrame**: 2-D subspace squared mahalanobis distances
                 that exceed the `l2_crit_val` threshold

   .. note::

      Noise realizations are added to `sim_en` to account for measurement
          noise.


.. function:: _l2_maha_worker(o1, o2names, mean, var, cov, results, l2_crit_val)


.. py:class:: Cov(x=None, names=[], row_names=[], col_names=[], isdiagonal=False, autoalign=True)

   Bases: :class:`pyemu.mat.mat_handler.Matrix`

   Diagonal and/or dense Covariance matrices

   :param x: numeric values
   :type x: `numpy.ndarray`
   :param names: list of row and column names
   :type names: [`str`]
   :param isdigonal: flag if the Matrix is diagonal
   :type isdigonal: `bool`
   :param autoalign: flag to control the autoalignment of Matrix during
                     linear algebra operations
   :type autoalign: `bool`

   Example::

       data = np.random.random((10,10))
       names = ["par_{0}".format(i) for i in range(10)]
       mat = pyemu.Cov(x=data,names=names)
       mat.to_binary("mat.jco")

   .. note::

      `row_names` and `col_names` args are supported in the contructor
      so support inheritance.  However, users should only pass `names`

   .. method:: identity(self)
      :property:

      get an identity `Cov` of the same shape

      :returns: new `Cov` instance with identity matrix
      :rtype: `Cov`


   .. method:: zero(self)
      :property:

      get an instance of `Cov` with all zeros

      :returns: new `Cov` instance with zeros
      :rtype: `Cov`


   .. method:: condition_on(self, conditioning_elements)

      get a new Covariance object that is conditional on knowing some
      elements.  uses Schur's complement for conditional Covariance
      propagation

      :param conditioning_elements: list of names of elements to condition on
      :type conditioning_elements: ['str']

      :returns: new conditional `Cov` that assumes `conditioning_elements` have become known
      :rtype: `Cov`


   .. method:: names(self)
      :property:

      wrapper for getting row_names.  row_names == col_names for Cov

      :returns: list of names
      :rtype: [`str`]


   .. method:: replace(self, other)

      replace elements in the covariance matrix with elements from other.
      if other is not diagonal, then this `Cov` becomes non diagonal

      :param `Cov`: the Cov to replace elements in this `Cov` with

      .. note:: operates in place


   .. method:: to_uncfile(self, unc_file, covmat_file='cov.mat', var_mult=1.0, include_path=True)

      write a PEST-compatible uncertainty file

      :param unc_file: filename of the uncertainty file
      :type unc_file: `str`
      :param covmat_file: covariance matrix filename. Default is
                          "Cov.mat".  If None, and Cov.isdiaonal, then a standard deviation
                          form of the uncertainty file is written.  Exception raised if `covmat_file` is `None`
                          and not `Cov.isdiagonal`
      :type covmat_file: `str`
      :param var_mult: variance multiplier for the covmat_file entry
      :type var_mult: `float`

      Example::

          cov = pyemu.Cov.from_parameter_data(pst)
          cov.to_uncfile("my.unc")


   .. method:: from_obsweights(cls, pst_file)
      :classmethod:

      instantiates a `Cov` instance from observation weights in
      a PEST control file.

      :param pst_file: pest control file name
      :type pst_file: `str`

      :returns: a diagonal observation noise covariance matrix derived from the
                weights in the pest control file.  Zero-weighted observations
                are included with a weight of 1.0e-30
      :rtype: `Cov`

      .. note:: Calls `Cov.from_observation_data()`

      Example::

          obscov = pyemu.Cov.from_obsweights("my.pst")



   .. method:: from_observation_data(cls, pst)
      :classmethod:

      instantiates a `Cov` from pyemu.Pst.observation_data

      :param pst: control file instance
      :type pst: `pyemu.Pst`

      :returns: a diagonal observation noise covariance matrix derived from the
                weights in the pest control file.  Zero-weighted observations
                are included with a weight of 1.0e-30
      :rtype: `Cov`

      Example::

          obscov = pyemu.Cov.from_observation_data(pst)


   .. method:: from_parbounds(cls, pst_file, sigma_range=4.0, scale_offset=True)
      :classmethod:

      Instantiates a `Cov` from a pest control file parameter data section using
      parameter bounds as a proxy for uncertainty.


      :param pst_file: pest control file name
      :type pst_file: `str`
      :param sigma_range: defines range of upper bound - lower bound in terms of standard
                          deviation (sigma). For example, if sigma_range = 4, the bounds
                          represent 4 * sigma.  Default is 4.0, representing approximately
                          95% confidence of implied normal distribution
      :type sigma_range: `float`
      :param scale_offset: flag to apply scale and offset to parameter upper and lower
                           bounds before calculating varaince. In some cases, not applying scale and
                           offset can result in undefined (log) variance.  Default is True.
      :type scale_offset: `bool`

      :returns: diagonal parameter `Cov` matrix created from parameter bounds
      :rtype: `Cov`

      .. note:: Calls `Cov.from_parameter_data()`


   .. method:: from_parameter_data(cls, pst, sigma_range=4.0, scale_offset=True)
      :classmethod:

      Instantiates a `Cov` from a pest control file parameter data section using
      parameter bounds as a proxy for uncertainty.


      :param pst_file: pest control file name
      :type pst_file: `str`
      :param sigma_range: defines range of upper bound - lower bound in terms of standard
                          deviation (sigma). For example, if sigma_range = 4, the bounds
                          represent 4 * sigma.  Default is 4.0, representing approximately
                          95% confidence of implied normal distribution
      :type sigma_range: `float`
      :param scale_offset: flag to apply scale and offset to parameter upper and lower
                           bounds before calculating varaince. In some cases, not applying scale and
                           offset can result in undefined (log) variance.  Default is True.
      :type scale_offset: `bool`

      :returns: diagonal parameter `Cov` matrix created from parameter bounds
      :rtype: `Cov`

      .. note:: Calls `Cov.from_parameter_data()`


   .. method:: from_uncfile(cls, filename)
      :classmethod:

      instaniates a `Cov` from a PEST-compatible uncertainty file

      :param filename: uncertainty file name
      :type filename: `str`

      :returns: `Cov` instance from uncertainty file
      :rtype: `Cov`

      Example::

          cov = pyemu.Cov.from_uncfile("my.unc")


   .. method:: _get_uncfile_dimensions(filename)
      :staticmethod:

      quickly read an uncertainty file to find the dimensions


   .. method:: identity_like(cls, other)
      :classmethod:

      Get an identity matrix Cov instance like other `Cov`

      :param other: other matrix - must be square
      :type other: `Matrix`

      :returns: new identity matrix `Cov` with shape of `other`
      :rtype: `Cov`


   .. method:: to_pearson(self)

      Convert Cov instance to Pearson correlation coefficient
      matrix

      :returns: A `Matrix` of correlation coefs.  Return type is `Matrix`
                on purpose so that it is clear the returned instance is not a Cov
      :rtype: `Matrix`



.. function:: pp_file_to_dataframe(pp_filename)

   read a pilot point file to a pandas Dataframe

   :param pp_filename: path and name of an existing pilot point file
   :type pp_filename: `str`

   :returns: a dataframe with `pp_utils.PP_NAMES` for columns
   :rtype: `pandas.DataFrame`

   Example::

       df = pyemu.pp_utils.pp_file_to_dataframe("my_pp.dat")


.. py:exception:: PyemuWarning

   Bases: :class:`RuntimeWarning`

   Base class for warnings about dubious runtime behavior.


.. data:: EPSILON
   :annotation: = 1e-07

   

.. py:class:: GeoStruct(nugget=0.0, variograms=[], name='struct1', transform='none')

   Bases: :class:`object`

   a geostatistical structure object that mimics the behavior of a PEST
   geostatistical structure.  The object contains variogram instances and
   (optionally) nugget information.

   :param nugget: nugget contribution. Default is 0.0
   :type nugget: `float` (optional)
   :param variograms: ([`pyemu.Vario2d`] (optional)): variogram(s) associated
                      with this GeoStruct instance. Default is empty list
   :param name: name to assign the structure.  Default
                is "struct1".
   :type name: `str` (optional)
   :param transform: the transformation to apply to
                     the GeoStruct.  Can be "none" or "log", depending on the
                     transformation of the property being represented by the `GeoStruct`.
                     Default is "none"
   :type transform: `str` (optional)

   Example::

       v = pyemu.utils.geostats.ExpVario(a=1000,contribution=1.0)
       gs = pyemu.utils.geostats.GeoStruct(variograms=v,nugget=0.5)

   .. attribute:: nugget
      

      the nugget effect contribution

      :type: `float`


   .. attribute:: variograms
      

      a list of variogram instances

      :type: [`pyemu.utils.geostats.Vario2d`]


   .. attribute:: transform
      

      the transformation of the `GeoStruct`.  Can be 'log' or 'none'

      :type: `str`


   .. method:: __lt__(self, other)

      Return self<value.


   .. method:: __gt__(self, other)

      Return self>value.


   .. method:: same_as_other(self, other)


   .. method:: to_struct_file(self, f)

      write a PEST-style structure file

      :param f: file to write the GeoStruct information in to.  Can
                also be an open file handle
      :type f: `str`


   .. method:: covariance_matrix(self, x, y, names=None, cov=None)

      build a `pyemu.Cov` instance from `GeoStruct`

      :param x: x-coordinate locations
      :type x: [`floats`]
      :param y: y-coordinate locations
      :type y: [`float`]
      :param names: names of location. If None,
                    cov must not be None.  Default is None.
      :type names: [`str`] (optional)
      :param cov: an existing Cov instance.  The contribution
                  of this GeoStruct is added to cov.  If cov is None,
                  names must not be None. Default is None
      :type cov: `pyemu.Cov`

      :returns: the covariance matrix implied by this
                GeoStruct for the x,y pairs. `cov` has row and column
                names supplied by the names argument unless the "cov"
                argument was passed.
      :rtype: `pyemu.Cov`

      .. note::

         either "names" or "cov" must be passed.  If "cov" is passed, cov.shape
         must equal len(x) and len(y).

      Example::

          pp_df = pyemu.pp_utils.pp_file_to_dataframe("hkpp.dat")
          cov = gs.covariance_matrix(pp_df.x,pp_df.y,pp_df.name)
          cov.to_binary("cov.jcb")



   .. method:: covariance(self, pt0, pt1)

      get the covariance between two points implied by the `GeoStruct`.
      This is used during the ordinary kriging process to get the RHS

      :param pt0: xy-pair
      :type pt0: [`float`]
      :param pt1: xy-pair
      :type pt1: [`float`]

      :returns: the covariance between pt0 and pt1 implied
                by the GeoStruct
      :rtype: `float`


   .. method:: covariance_points(self, x0, y0, xother, yother)

      Get the covariance between point (x0,y0) and the points
      contained in xother, yother.

      :param x0: x-coordinate
      :type x0: `float`
      :param y0: y-coordinate
      :type y0: `float`
      :param xother: x-coordinates of other points
      :type xother: [`float`]
      :param yother: y-coordinates of other points
      :type yother: [`float`]

      :returns: a 1-D array of covariance between point x0,y0 and the
                points contained in xother, yother.  len(cov) = len(xother) =
                len(yother)
      :rtype: `numpy.ndarray`


   .. method:: sill(self)
      :property:

      get the sill of the `GeoStruct`

      :returns: the sill of the (nested) `GeoStruct`, including
                nugget and contribution from each variogram
      :rtype: `float`


   .. method:: plot(self, **kwargs)

      make a cheap plot of the `GeoStruct`

      :param \*\*kwargs: (dict)
                         keyword arguments to use for plotting.

      :returns: the axis with the GeoStruct plot
      :rtype: `matplotlib.pyplot.axis`

      .. note::

         optional arguments include "ax" (an existing axis),
         "individuals" (plot each variogram on a separate axis),
         "legend" (add a legend to the plot(s)).  All other kwargs
         are passed to matplotlib.pyplot.plot()


   .. method:: __str__(self)

      the `str` representation of the `GeoStruct`

      :returns: the string representation of the GeoStruct
      :rtype: `str`



.. py:class:: SpecSim2d(delx, dely, geostruct)

   Bases: :class:`object`

   2-D unconditional spectral simulation for regular grids

   :param delx: a 1-D array of x-dimension cell centers
                (or leading/trailing edges).  Only the distance between points
                is important
   :type delx: `numpy.ndarray`
   :param dely: a 1-D array of y-dimension cell centers
                (or leading/trailing edges).  Only the distance between points
                is important
   :type dely: `numpy.ndarray`
   :param geostruct: geostatistical structure instance
   :type geostruct: `pyemu.geostats.Geostruct`

   Example::

       v = pyemu.utils.geostats.ExpVario(a=1000,contribution=1.0)
       gs = pyemu.utils.geostats.GeoStruct(variograms=v,nugget=0.5)
       delx,dely = np.arange(100), np.arrange(100)
       ss = pyemu.utils.geostats.SpecSim2d(delx,dely,gs)
       arrays = ss.draw(num_reals=100)

   .. method:: grid_is_regular(delx, dely, tol=0.0001)
      :staticmethod:

      check that a grid is regular using delx and dely vectors

      :param delx: `numpy.ndarray`
                   a 1-D array of x-dimension cell centers (or leading/trailing edges).  Only the
                   distance between points is important
      :param dely: `numpy.ndarray`
                   a 1-D array of y-dimension cell centers (or leading/trailing edges).  Only the
                   distance between points is important
      :param tol: `float` (optional)
                  tolerance to determine grid regularity.  Default is 1.0e-4

      :returns: flag indicating if the grid defined by `delx` and `dely` is regular
      :rtype: `bool`


   .. method:: initialize(self)

      prepare for spectral simulation.

      .. note::

         `initialize()` prepares for simulation by undertaking
         the fast FFT on the wave number matrix and should be called
         if the `SpecSim2d.geostruct` is changed.
         
         This method is called by the constructor.


   .. method:: draw_arrays(self, num_reals=1, mean_value=1.0)

      draw realizations

      :param num_reals: number of realizations to generate
      :type num_reals: `int`
      :param mean_value: the mean value of the realizations
      :type mean_value: `float`

      :returns: a 3-D array of realizations.  Shape
                is (num_reals,self.dely.shape[0],self.delx.shape[0])
      :rtype: `numpy.ndarray`

      .. note::

         log transformation is respected and the returned `reals` array is
         in arithmatic space


   .. method:: grid_par_ensemble_helper(self, pst, gr_df, num_reals, sigma_range=6, logger=None)

      wrapper around `SpecSim2d.draw()` designed to support `pyemu.PstFromFlopy`
          grid-based parameters

      :param pst: a control file instance
      :type pst: `pyemu.Pst`
      :param gr_df: a dataframe listing `parval1`,
                    `pargp`, `i`, `j` for each grid based parameter
      :type gr_df: `pandas.DataFrame`
      :param num_reals: number of realizations to generate
      :type num_reals: `int`
      :param sigma_range: number of standard deviations
                          implied by parameter bounds in control file. Default is 6
      :type sigma_range: `float` (optional)
      :param logger: a logger instance for logging
      :type logger: `pyemu.Logger` (optional)

      :returns: an untransformed parameter ensemble of
                realized grid-parameter values
      :rtype: `pyemu.ParameterEnsemble`

      .. note::

         the method processes each unique `pargp` value in `gr_df` and resets the sill of `self.geostruct` by
         the maximum bounds-implied variance of each `pargp`.  This method makes repeated calls to
         `self.initialize()` to deal with the geostruct changes.


   .. method:: draw_conditional(self, seed, obs_points, sg, base_values_file, local=True, factors_file=None, num_reals=1, mean_value=1.0, R_factor=1.0)

      Generate a conditional, correlated random field using the Spec2dSim
          object, a set of observation points, and a factors file.

          The conditional field is made by generating an unconditional correlated random
          field that captures the covariance in the variogram and conditioning it by kriging
          a second surface using the value of the random field as observations.
          This second conditioning surface provides an estimate of uncertainty (kriging error)
          away from the observation points. At the observation points, the kriged surface is
          equal to (less nugget effects) the observation. The conditioned correlated field
          is then generated using: T(x) = Z(x) + [S(x) − S∗(x)]
          where T(x) is the conditioned simulation, Z(x) is a kriging estimator of the
          unknown field, S(x) is an unconditioned random field with the same covariance
          structure as the desired field, and S∗(x) is a kriging estimate of the unconditioned
          random field using its values at the observation points (pilot points).
          [S(x) − S∗(x)] is an estimate of the kriging error.

          This approach makes T(x) match the observed values at the observation points
          (x_a, y_z), T(a) = Z(a), and have a structure away from the observation points that
          follows the variogram used to generate Z, S, and S∗.

          Chiles, J-P, and Delfiner, P., Geostatistics- Modeling Spatial Uncertainty: Wiley,
              London, 695 p.

      :param seed: integer used for random seed.  If seed is used as a PEST parameter,
                   then passing the same value for seed will yield the same
                   conditioned random fields. This allows runs to be recreated
                   given an ensemble of seeds.
      :type seed: `int`
      :param obs_points: locations for observation points.
                         Either filename in pyemupilot point file format:
                         ["name","x","y","zone","parval1"] ora dataframe with these columns.
                         Note that parval1 is not used.
      :type obs_points: `str` or `dataframe`
      :param base_values_file: filename containing 2d array with the base
                               parameter values from which the random field will depart (Z(x)) above.
                               Values of Z(x) are used for conditioning, not parval1 in the
                               observation point file.
      :type base_values_file: `str`
      :param factors_file: name of the factors file generated using the
                           locations of the observation points and the target grid.
                           If None this file will be generated and called conditional_factors.dat;
                           but this is a slow step and should not generally be called for every simulation.
      :type factors_file: `str`
      :param sg: flopy StructuredGrid object
      :param local: whether coordinates in obs_points are in local (model) or map coordinates
      :type local: `boolean`
      :param num_reals: number of realizations to generate
      :type num_reals: `int`
      :param mean_value: the mean value of the realizations
      :type mean_value: `float`
      :param R_factor: a factor to scale the field, sometimes the variation from the
                       geostruct parameters is larger or smaller than desired.
      :type R_factor: `float`

      :returns:

                a 3-D array of realizations.  Shape is
                    (num_reals, self.dely.shape[0], self.delx.shape[0])
      :rtype: `numpy.ndarray`

      .. note::

         log transformation is respected and the returned `reals`
             array is in arithmetic space



.. py:class:: OrdinaryKrige(geostruct, point_data)

   Bases: :class:`object`

   Ordinary Kriging using Pandas and Numpy.

   :param geostruct: a pyemu.geostats.GeoStruct to use for the kriging
   :type geostruct: `GeoStruct`
   :param point_data: the conditioning points to use for kriging.
                      `point_data` must contain columns "name", "x", "y".
   :type point_data: `pandas.DataFrame`

   .. note::

      if `point_data` is an `str`, then it is assumed to be a pilot points file
      and is loaded as such using `pyemu.pp_utils.pp_file_to_dataframe()`
      
      If zoned interpolation is used for grid-based interpolation, then
      `point_data` must also contain a "zone" column

   Example::

       import pyemu
       v = pyemu.utils.geostats.ExpVario(a=1000,contribution=1.0)
       gs = pyemu.utils.geostats.GeoStruct(variograms=v,nugget=0.5)
       pp_df = pyemu.pp_utils.pp_file_to_dataframe("hkpp.dat")
       ok = pyemu.utils.geostats.OrdinaryKrige(gs,pp_df)

   .. method:: check_point_data_dist(self, rectify=False)

      check for point_data entries that are closer than
      EPSILON distance - this will cause a singular kriging matrix.

      :param rectify: flag to fix the problems with point_data
                      by dropping additional points that are
                      closer than EPSILON distance.  Default is False
      :type rectify: `bool`

      .. note::

         this method will issue warnings for points that are closer
         than EPSILON distance


   .. method:: calc_factors_grid(self, spatial_reference, zone_array=None, minpts_interp=1, maxpts_interp=20, search_radius=10000000000.0, verbose=False, var_filename=None, forgive=False, num_threads=1)

      calculate kriging factors (weights) for a structured grid.

      :param spatial_reference: a spatial
                                reference that describes the orientation and
                                spatail projection of the the structured grid
      :type spatial_reference: `flopy.utils.reference.SpatialReference`
      :param zone_array: an integer array of zones to use for kriging.
                         If not None, then `point_data` must also contain a "zone" column.  `point_data`
                         entries with a zone value not found in zone_array will be skipped.
                         If None, then all `point_data` will (potentially) be used for
                         interpolating each grid node. Default is None
      :type zone_array: `numpy.ndarray`
      :param minpts_interp: minimum number of `point_data` entires to use for interpolation at
                            a given grid node.  grid nodes with less than `minpts_interp`
                            `point_data` found will be skipped (assigned np.NaN).  Defaut is 1
      :type minpts_interp: `int`
      :param maxpts_interp: a given grid node.  A larger `maxpts_interp` will yield "smoother"
                            interplation, but using a large `maxpts_interp` will slow the
                            (already) slow kriging solution process and may lead to
                            memory errors. Default is 20.
      :type maxpts_interp: `int`
      :param search_radius: `point_data` entries. Default is 1.0e+10
      :type search_radius: `float`
      :param verbose: (`bool`): a flag to  echo process to stdout during the interpolatino process.
                      Default is False
      :param var_filename: a filename to save the kriging variance for each interpolated grid node.
                           Default is None.
      :type var_filename: `str`
      :param forgive: flag to continue if inversion of the kriging matrix failes at one or more
                      grid nodes.  Inversion usually fails if the kriging matrix is singular,
                      resulting from `point_data` entries closer than EPSILON distance.  If True,
                      warnings are issued for each failed inversion.  If False, an exception
                      is raised for failed matrix inversion.
      :type forgive: `bool`
      :param num_threads: number of multiprocessing workers to use to try to speed up
                          kriging in python.  Default is 1.
      :type num_threads: `int`

      :returns: a dataframe with information summarizing the ordinary kriging
                process for each grid node
      :rtype: `pandas.DataFrame`

      .. note::

         this method calls OrdinaryKrige.calc_factors()
         
         this method is the main entry point for grid-based kriging factor generation

      Example::

          import flopy

          import pyemu
          v = pyemu.utils.geostats.ExpVario(a=1000,contribution=1.0)
          gs = pyemu.utils.geostats.GeoStruct(variograms=v,nugget=0.5)
          pp_df = pyemu.pp_utils.pp_file_to_dataframe("hkpp.dat")
          ok = pyemu.utils.geostats.OrdinaryKrige(gs,pp_df)
          m = flopy.modflow.Modflow.load("mymodel.nam")
          df = ok.calc_factors_grid(m.sr,zone_array=m.bas6.ibound[0].array,
                                    var_filename="ok_var.dat")
          ok.to_grid_factor_file("factors.dat")


   .. method:: _dist_calcs(self, ix, iy, ptx_array, pty_array, ptnames, sqradius)

      private: find nearby points


   .. method:: _cov_points(self, ix, iy, pt_names)

      private: get covariance between points


   .. method:: _form(self, pt_names, point_cov, interp_cov)

      private: form the kriging equations


   .. method:: _solve(self, A, rhs)


   .. method:: calc_factors(self, x, y, minpts_interp=1, maxpts_interp=20, search_radius=10000000000.0, verbose=False, pt_zone=None, forgive=False, num_threads=1)

      calculate ordinary kriging factors (weights) for the points
      represented by arguments x and y

      :param x: x-coordinates to calculate kriging factors for
      :type x: [`float`]
      :param y: y-coordinates to calculate kriging factors for
      :type y: ([`float`]
      :param minpts_interp: minimum number of point_data entires to use for interpolation at
                            a given x,y interplation point.  interpolation points with less
                            than `minpts_interp` `point_data` found will be skipped
                            (assigned np.NaN).  Defaut is 1
      :type minpts_interp: `int`
      :param maxpts_interp: maximum number of point_data entries to use for interpolation at
                            a given x,y interpolation point.  A larger `maxpts_interp` will
                            yield "smoother" interplation, but using a large `maxpts_interp`
                            will slow the (already) slow kriging solution process and may
                            lead to memory errors. Default is 20.
      :type maxpts_interp: `int`
      :param search_radius: the size of the region around a given x,y
                            interpolation point to search for `point_data` entries. Default is 1.0e+10
      :type search_radius: `float`
      :param verbose: a flag to  echo process to stdout during the interpolatino process.
                      Default is False
      :type verbose: `bool`
      :param forgive: flag to continue if inversion of the kriging matrix failes at one or more
                      interpolation points.  Inversion usually fails if the kriging matrix is singular,
                      resulting from `point_data` entries closer than EPSILON distance.  If True,
                      warnings are issued for each failed inversion.  If False, an exception
                      is raised for failed matrix inversion.
      :type forgive: `bool`
      :param num_threads: number of multiprocessing workers to use to try to speed up
                          kriging in python.  Default is 1.
      :type num_threads: `int`

      :returns: a dataframe with information summarizing the ordinary kriging
                process for each interpolation points
      :rtype: `pandas.DataFrame`

      .. note::

         this method calls either `OrdinaryKrige.calc_factors_org()` or
         `OrdinaryKrige.calc_factors_mp()` depending on the value of `num_threads`


   .. method:: _calc_factors_org(self, x, y, minpts_interp=1, maxpts_interp=20, search_radius=10000000000.0, verbose=False, pt_zone=None, forgive=False)


   .. method:: _calc_factors_mp(self, x, y, minpts_interp=1, maxpts_interp=20, search_radius=10000000000.0, verbose=False, pt_zone=None, forgive=False, num_threads=1)


   .. method:: _worker(ithread, point_data, point_pairs, inames, idist, ifacts, err_var, point_cov_df, geostruct, epsilon, search_radius, pt_zone, minpts_interp, maxpts_interp, lock)
      :staticmethod:


   .. method:: to_grid_factors_file(self, filename, points_file='points.junk', zone_file='zone.junk')

      write a grid-based PEST-style factors file.  This file can be used with
      the fac2real() method to write an interpolated structured array

      :param filename: factor filename
      :type filename: `str`
      :param points_file: points filename to add to the header of the factors file.
                          This is not used by the fac2real() method.  Default is "points.junk"
      :type points_file: `str`
      :param zone_file: zone filename to add to the header of the factors file.
                        This is notused by the fac2real() method.  Default is "zone.junk"
      :type zone_file: `str`

      .. note:: this method should be called after OrdinaryKirge.calc_factors_grid()



.. py:class:: Vario2d(contribution, a, anisotropy=1.0, bearing=0.0, name='var1')

   Bases: :class:`object`

   base class for 2-D variograms.

   :param contribution: sill of the variogram
   :type contribution: float
   :param a: (practical) range of correlation
   :type a: `float`
   :param anisotropy: Anisotropy ratio. Default is 1.0
   :type anisotropy: `float`, optional
   :param bearing: (`float`, optional): angle in degrees East of North corresponding
                   to anisotropy ellipse. Default is 0.0
   :param name: name of the variogram.  Default is "var1"
   :type name: `str`, optinoal

   .. note::

      This base class should not be instantiated directly as it does not implement
      an h_function() method.

   .. method:: same_as_other(self, other)


   .. method:: to_struct_file(self, f)

      write the `Vario2d` to a PEST-style structure file

      :param f: filename to write to.  `f` can also be an open
                file handle.
      :type f: `str`


   .. method:: bearing_rads(self)
      :property:

      get the bearing of the Vario2d in radians

      :returns: the Vario2d bearing in radians
      :rtype: `float`


   .. method:: rotation_coefs(self)
      :property:

      get the rotation coefficents in radians

      :returns: the rotation coefficients implied by `Vario2d.bearing`
      :rtype: [`float`]


   .. method:: inv_h(self, h)

      the inverse of the h_function.  Used for plotting

      :param h: the value of h_function to invert
      :type h: `float`

      :returns: the inverse of h
      :rtype: `float`


   .. method:: plot(self, **kwargs)

      get a cheap plot of the Vario2d

      :param \*\*kwargs: keyword arguments to use for plotting
      :type \*\*kwargs: `dict`

      :returns: `matplotlib.pyplot.axis`

      .. note::

         optional arguments in kwargs include
         "ax" (existing `matplotlib.pyplot.axis`).  Other
         kwargs are passed to `matplotlib.pyplot.plot()`


   .. method:: covariance_matrix(self, x, y, names=None, cov=None)

      build a pyemu.Cov instance implied by Vario2d

      :param x: x-coordinate locations
      :type x: [`float`]
      :param y: y-coordinate locations
      :type y: [`float`]
      :param names: names of locations. If None, cov must not be None
      :type names: [`str`]
      :param cov: an existing Cov instance.  Vario2d contribution is added to cov
      :type cov: `pyemu.Cov`
      :param in place:

      :returns: the covariance matrix for `x`, `y` implied by `Vario2d`
      :rtype: `pyemu.Cov`

      .. note:: either `names` or `cov` must not be None.


   .. method:: _specsim_grid_contrib(self, grid)


   .. method:: _apply_rotation(self, dx, dy)

      private method to rotate points
      according to Vario2d.bearing and Vario2d.anisotropy



   .. method:: covariance_points(self, x0, y0, xother, yother)

      get the covariance between base point (x0,y0) and
      other points xother,yother implied by `Vario2d`

      :param x0: x-coordinate
      :type x0: `float`
      :param y0: y-coordinate
      :type y0: `float`
      :param xother: x-coordinates of other points
      :type xother: [`float`]
      :param yother: y-coordinates of other points
      :type yother: [`float`]

      :returns: a 1-D array of covariance between point x0,y0 and the
                points contained in xother, yother.  len(cov) = len(xother) =
                len(yother)
      :rtype: `numpy.ndarray`


   .. method:: covariance(self, pt0, pt1)

      get the covarince between two points implied by Vario2d

      :param pt0: ([`float`]): first point x and y
      :param pt1: ([`float`]): second point x and y

      :returns: covariance between pt0 and pt1
      :rtype: `float`


   .. method:: __str__(self)

      get the str representation of Vario2d

      :returns: string rep
      :rtype: `str`



.. py:class:: ExpVario(contribution, a, anisotropy=1.0, bearing=0.0, name='var1')

   Bases: :class:`pyemu.utils.geostats.Vario2d`

   Gaussian variogram derived type

   :param contribution: sill of the variogram
   :type contribution: float
   :param a: (practical) range of correlation
   :type a: `float`
   :param anisotropy: Anisotropy ratio. Default is 1.0
   :type anisotropy: `float`, optional
   :param bearing: (`float`, optional): angle in degrees East of North corresponding
                   to anisotropy ellipse. Default is 0.0
   :param name: name of the variogram.  Default is "var1"
   :type name: `str`, optinoal

   Example::

       v = pyemu.utils.geostats.ExpVario(a=1000,contribution=1.0)


   .. method:: _h_function(self, h)

      private method exponential variogram "h" function



.. py:class:: GauVario(contribution, a, anisotropy=1.0, bearing=0.0, name='var1')

   Bases: :class:`pyemu.utils.geostats.Vario2d`

   Gaussian variogram derived type

   :param contribution: sill of the variogram
   :type contribution: float
   :param a: (practical) range of correlation
   :type a: `float`
   :param anisotropy: Anisotropy ratio. Default is 1.0
   :type anisotropy: `float`, optional
   :param bearing: (`float`, optional): angle in degrees East of North corresponding
                   to anisotropy ellipse. Default is 0.0
   :param name: name of the variogram.  Default is "var1"
   :type name: `str`, optinoal

   Example::

       v = pyemu.utils.geostats.GauVario(a=1000,contribution=1.0)

   .. note:: the Gaussian variogram can be unstable (not invertible) for long ranges.

   .. method:: _h_function(self, h)

      private method for the gaussian variogram "h" function




.. py:class:: SphVario(contribution, a, anisotropy=1.0, bearing=0.0, name='var1')

   Bases: :class:`pyemu.utils.geostats.Vario2d`

   Spherical variogram derived type

   :param contribution: sill of the variogram
   :type contribution: float
   :param a: (practical) range of correlation
   :type a: `float`
   :param anisotropy: Anisotropy ratio. Default is 1.0
   :type anisotropy: `float`, optional
   :param bearing: (`float`, optional): angle in degrees East of North corresponding
                   to anisotropy ellipse. Default is 0.0
   :param name: name of the variogram.  Default is "var1"
   :type name: `str`, optinoal

    Example::

        v = pyemu.utils.geostats.SphVario(a=1000,contribution=1.0)


   .. method:: _h_function(self, h)

      private method for the spherical variogram "h" function




.. function:: read_struct_file(struct_file, return_type=GeoStruct)

   read an existing PEST-type structure file into a GeoStruct instance

   :param struct_file: existing pest-type structure file
   :type struct_file: `str`
   :param return_type: the instance type to return.  Default is GeoStruct
   :type return_type: `object`

   :returns: list of `GeoStruct` instances.  If
             only one `GeoStruct` is in the file, then a `GeoStruct` is returned
   :rtype: [`pyemu.GeoStruct`]

   Example::

       gs = pyemu.utils.geostats.reads_struct_file("struct.dat")



.. function:: _read_variogram(f)

   Function to instantiate a Vario2d from a PEST-style structure file




.. function:: _read_structure_attributes(f)

   function to read information from a PEST-style structure file




.. function:: read_sgems_variogram_xml(xml_file, return_type=GeoStruct)

   function to read an SGEMS-type variogram XML file into
   a `GeoStruct`

   :param xml_file: SGEMS variogram XML file
   :type xml_file: `str`
   :param return_type: the instance type to return.  Default is `GeoStruct`
   :type return_type: `object`

   :returns: `GeoStruct`
   :rtype: gs

   Example::

       gs = pyemu.utils.geostats.read_sgems_variogram_xml("sgems.xml")


.. function:: gslib_2_dataframe(filename, attr_name=None, x_idx=0, y_idx=1)

   function to read a GSLIB point data file into a pandas.DataFrame

   :param filename: GSLIB file
   :type filename: `str`
   :param attr_name: the column name in the dataframe for the attribute.
                     If None, GSLIB file can have only 3 columns.  `attr_name` must be in
                     the GSLIB file header
   :type attr_name: `str`
   :param x_idx: the index of the x-coordinate information in the GSLIB file. Default is
                 0 (first column)
   :type x_idx: `int`
   :param y_idx: the index of the y-coordinate information in the GSLIB file.
                 Default is 1 (second column)
   :type y_idx: `int`

   :returns: a dataframe of info from the GSLIB file
   :rtype: `pandas.DataFrame`

   .. note:: assigns generic point names ("pt0, pt1, etc)

   Example::

       df = pyemu.utiils.geostats.gslib_2_dataframe("prop.gslib",attr_name="hk")



.. function:: load_sgems_exp_var(filename)

   read an SGEM experimental variogram into a sequence of
   pandas.DataFrames

   :param filename: an SGEMS experimental variogram XML file
   :type filename: `str`

   :returns: a list of pandas.DataFrames of x, y, pairs for each
             division in the experimental variogram
   :rtype: [`pandas.DataFrame`]


.. function:: fac2real(pp_file=None, factors_file='factors.dat', out_file='test.ref', upper_lim=1e+30, lower_lim=-1e+30, fill_value=1e+30)

   A python replication of the PEST fac2real utility for creating a
   structure grid array from previously calculated kriging factors (weights)

   :param pp_file: PEST-type pilot points file
   :type pp_file: `str`
   :param factors_file: PEST-style factors file
   :type factors_file: `str`
   :param out_file: filename of array to write.  If None, array is returned, else
                    value of out_file is returned.  Default is "test.ref".
   :type out_file: `str`
   :param upper_lim: maximum interpolated value in the array.  Values greater than
                     `upper_lim` are set to fill_value
   :type upper_lim: `float`
   :param lower_lim: minimum interpolated value in the array.  Values less than
                     `lower_lim` are set to fill_value
   :type lower_lim: `float`
   :param fill_value: the value to assign array nodes that are not interpolated
   :type fill_value: `float`

   :returns: if out_file is None

             `str`: if out_file it not None
   :rtype: `numpy.ndarray`

   Example::

       pyemu.utils.geostats.fac2real("hkpp.dat",out_file="hk_layer_1.ref")


.. function:: _parse_factor_line(line)

   function to parse a factor file line.  Used by fac2real()


.. data:: max_colwidth
   :annotation: = 100

   

.. function:: SFMT(item)


.. data:: IFMT
   

   

.. data:: FFMT
   

   

.. data:: pst_config
   

   

.. function:: run(cmd_str, cwd='.', verbose=False)

   an OS agnostic function to execute a command line

   :param cmd_str: the str to execute with `os.system()`
   :type cmd_str: `str`
   :param cwd: the directory to execute the command in.
               Default is ".".
   :type cwd: `str`, optional
   :param verbose: flag to echo to stdout the  `cmd_str`.
                   Default is `False`.
   :type verbose: `bool`, optional

   .. rubric:: Notes

   uses `platform` to detect OS and adds .exe suffix or ./ prefix as appropriate
   if `os.system` returns non-zero, an exception is raised

   Example::

       pyemu.os_utils.run("pestpp-ies my.pst",cwd="template")


.. function:: _write_df_tpl(filename, df, sep=',', tpl_marker='~', **kwargs)

   function write a pandas dataframe to a template file.



.. py:exception:: PyemuWarning

   Bases: :class:`RuntimeWarning`

   Base class for warnings about dubious runtime behavior.


.. data:: PP_FMT
   

   

.. data:: PP_NAMES
   :annotation: = ['name', 'x', 'y', 'zone', 'parval1']

   

.. function:: setup_pilotpoints_grid(ml=None, sr=None, ibound=None, prefix_dict=None, every_n_cell=4, ninst=1, use_ibound_zones=False, pp_dir='.', tpl_dir='.', shapename='pp.shp', longnames=False)

   setup a regularly-spaced (gridded) pilot point parameterization

   :param ml: a flopy mbase dervied type.  If None, `sr` must not be None.
   :type ml: `flopy.mbase`, optional
   :param sr: a spatial reference use to
              locate the model grid in space.  If None, `ml` must not be None.  Default is None
   :type sr: `flopy.utils.reference.SpatialReference`, optional
   :param ibound: the modflow ibound integer array.  THis is used to
                  set pilot points only in active areas. If None and ml is None, then pilot points
                  are set in all rows and columns according to `every_n_cell`.  Default is None.
   :type ibound: `numpy.ndarray`, optional
   :param prefix_dict: a dictionary of layer index, pilot point parameter prefix(es) pairs.
                       For example : `{0:["hk,"vk"]}` would setup pilot points with the prefix "hk" and "vk" for
                       model layer 1. If None, a generic set of pilot points with
                       the "pp" prefix are setup for a generic nrow by ncol grid. Default is None
   :type prefix_dict: `dict`
   :param ninst: Number of instances of pilot_points to set up.
                 e.g. number of layers. If ml is None and prefix_dict is None,
                 this is used to set up default prefix_dict.
   :type ninst: `int`
   :param use_ibound_zones: a flag to use the greater-than-zero values in the
                            ibound as pilot point zones.  If False ,ibound values greater than zero are
                            treated as a single zone.  Default is False.
   :type use_ibound_zones: `bool`
   :param pp_dir: directory to write pilot point files to.  Default is '.'
   :type pp_dir: `str`, optional
   :param tpl_dir: directory to write pilot point template file to.  Default is '.'
   :type tpl_dir: `str`, optional
   :param shapename: name of shapefile to write that contains pilot
                     point information. Default is "pp.shp"
   :type shapename: `str`, optional

   :returns: a dataframe summarizing pilot point information (same information
             written to `shapename`
   :rtype: `pandas.DataFrame`

   Example::

       m = flopy.modflow.Modflow.load("my.nam")
       df = pyemu.pp_utils.setup_pilotpoints_grid(ml=m)


.. function:: pp_file_to_dataframe(pp_filename)

   read a pilot point file to a pandas Dataframe

   :param pp_filename: path and name of an existing pilot point file
   :type pp_filename: `str`

   :returns: a dataframe with `pp_utils.PP_NAMES` for columns
   :rtype: `pandas.DataFrame`

   Example::

       df = pyemu.pp_utils.pp_file_to_dataframe("my_pp.dat")


.. function:: pp_tpl_to_dataframe(tpl_filename)

   read a pilot points template file to a pandas dataframe

   :param tpl_filename: path and name of an existing pilot points
                        template file
   :type tpl_filename: `str`

   :returns: a dataframe of pilot point info with "parnme" included
   :rtype: `pandas.DataFrame`

   .. rubric:: Notes

   Use for processing pilot points since the point point file itself may
   have generic "names".

   Example::

       df = pyemu.pp_utils.pp_tpl_file_to_dataframe("my_pp.dat.tpl")


.. function:: write_pp_shapfile(pp_df, shapename=None)

   write pilot points dataframe to a shapefile

   :param pp_df: pilot point dataframe (must include "x" and "y"
                 columns).  If `pp_df` is a string, it is assumed to be a pilot points file
                 and is loaded with `pp_utils.pp_file_to_dataframe`. Can also be a list of
                 `pandas.DataFrames` and/or filenames.
   :type pp_df: `pandas.DataFrame`
   :param shapename: the shapefile name to write.  If `None` , `pp_df` must be a string
                     and shapefile is saved as `pp_df` +".shp"
   :type shapename: `str`

   .. rubric:: Notes

   requires pyshp


.. function:: write_pp_file(filename, pp_df)

   write a pilot points dataframe to a pilot points file

   :param filename: pilot points file to write
   :type filename: `str`
   :param pp_df: a dataframe that has
                 at least columns "x","y","zone", and "value"
   :type pp_df: `pandas.DataFrame`


.. function:: pilot_points_to_tpl(pp_file, tpl_file=None, name_prefix=None, longnames=False)

   write a template file for a pilot points file

   :param pp_file: (`str`): existing pilot points file
   :param tpl_file: template file name to write.  If None,
                    `pp_file`+".tpl" is used.  Default is `None`.
   :type tpl_file: `str`
   :param name_prefix: name to prepend to parameter names for each
                       pilot point.  For example, if `name_prefix = "hk_"`, then each
                       pilot point parameters will be named "hk_0001","hk_0002", etc.
                       If None, parameter names from `pp_df.name` are used.
                       Default is None.
   :type name_prefix: `str`

   :returns: a dataframe with pilot point information
             (name,x,y,zone,parval1) with the parameter information
             (parnme,tpl_str)
   :rtype: `pandas.DataFrame`


.. data:: max_colwidth
   :annotation: = 100

   

.. function:: SFMT(item)


.. data:: IFMT
   

   

.. data:: FFMT
   

   

.. data:: pst_config
   

   

.. function:: parse_tpl_file(tpl_file)

   parse a PEST-style template file to get the parameter names

   Args:
   tpl_file (`str`): path and name of a template file

   :returns: list of parameter names found in `tpl_file`
   :rtype: [`str`]

   Example::

       par_names = pyemu.pst_utils.parse_tpl_file("my.tpl")


.. function:: try_process_output_file(ins_file, output_file=None)

   attempt to process a model output file using a PEST-style instruction file

   :param ins_file: path and name of an instruction file
   :type ins_file: `str`
   :param output_file: path and name of existing model
                       output file to process.  If `None`, `ins_file.replace(".ins","")`
                       is used.  Default is None.
   :type output_file: `str`,optional

   :returns: a dataframe of observation name and simulated outputs
             extracted from `output_file`.
   :rtype: `pandas.DataFrame`

   .. note::

      If an exception is raised when processing the output file, the exception
      is echoed to the screen and `None` is returned.

   Example::

       df = pyemu.pst_utils.try_process_output_file("my.ins","my.output")


.. function:: run(cmd_str, cwd='.', verbose=False)

   an OS agnostic function to execute a command line

   :param cmd_str: the str to execute with `os.system()`
   :type cmd_str: `str`
   :param cwd: the directory to execute the command in.
               Default is ".".
   :type cwd: `str`, optional
   :param verbose: flag to echo to stdout the  `cmd_str`.
                   Default is `False`.
   :type verbose: `bool`, optional

   .. rubric:: Notes

   uses `platform` to detect OS and adds .exe suffix or ./ prefix as appropriate
   if `os.system` returns non-zero, an exception is raised

   Example::

       pyemu.os_utils.run("pestpp-ies my.pst",cwd="template")


.. function:: _write_df_tpl(filename, df, sep=',', tpl_marker='~', **kwargs)

   function write a pandas dataframe to a template file.



.. py:exception:: PyemuWarning

   Bases: :class:`RuntimeWarning`

   Base class for warnings about dubious runtime behavior.


.. data:: PP_FMT
   

   

.. data:: PP_NAMES
   :annotation: = ['name', 'x', 'y', 'zone', 'parval1']

   

.. function:: modflow_pval_to_template_file(pval_file, tpl_file=None)

   write a template file for a modflow parameter value file.

   :param pval_file: the path and name of the existing modflow pval file
   :type pval_file: `str`
   :param tpl_file: template file to write. If None, use
                    `pval_file` +".tpl". Default is None
   :type tpl_file: `str`, optional

   .. note:: Uses names in the first column in the pval file as par names.

   :returns: a dataFrame with control file parameter information
   :rtype: **pandas.DataFrame**


.. function:: modflow_hob_to_instruction_file(hob_file, ins_file=None)

   write an instruction file for a modflow head observation file

   :param hob_file: the path and name of the existing modflow hob file
   :type hob_file: `str`
   :param ins_file: the name of the instruction file to write.
                    If `None`, `hob_file` +".ins" is used.  Default is `None`.
   :type ins_file: `str`, optional

   :returns: a dataFrame with control file observation information
   :rtype: **pandas.DataFrame**


.. function:: modflow_hydmod_to_instruction_file(hydmod_file, ins_file=None)

   write an instruction file for a modflow hydmod file

   :param hydmod_file: the path and name of the existing modflow hob file
   :type hydmod_file: `str`
   :param ins_file: the name of the instruction file to write.
                    If `None`, `hydmod_file` +".ins" is used.  Default is `None`.
   :type ins_file: `str`, optional

   :returns: a dataFrame with control file observation information
   :rtype: **pandas.DataFrame**

   .. note:: calls `pyemu.gw_utils.modflow_read_hydmod_file()`


.. function:: modflow_read_hydmod_file(hydmod_file, hydmod_outfile=None)

   read a binary hydmod file and return a dataframe of the results

   :param hydmod_file: The path and name of the existing modflow hydmod binary file
   :type hydmod_file: `str`
   :param hydmod_outfile: output file to write.  If `None`, use `hydmod_file` +".dat".
                          Default is `None`.
   :type hydmod_outfile: `str`, optional

   :returns: a dataFrame with hymod_file values
   :rtype: **pandas.DataFrame**


.. function:: setup_mtlist_budget_obs(list_filename, gw_filename='mtlist_gw.dat', sw_filename='mtlist_sw.dat', start_datetime='1-1-1970', gw_prefix='gw', sw_prefix='sw', save_setup_file=False)

   setup observations of gw (and optionally sw) mass budgets from mt3dusgs list file.

   :param list_filename: path and name of existing modflow list file
   :type list_filename: `str`
   :param gw_filename: output filename that will contain the gw budget
                       observations. Default is "mtlist_gw.dat"
   :type gw_filename: `str`, optional
   :param sw_filename: output filename that will contain the sw budget
                       observations. Default is "mtlist_sw.dat"
   :type sw_filename: `str`, optional
   :param start_datetime: an str that can be parsed into a `pandas.TimeStamp`.
                          used to give budget observations meaningful names.  Default is "1-1-1970".
   :type start_datetime: `str`, optional
   :param gw_prefix: a prefix to add to the GW budget observations.
                     Useful if processing more than one list file as part of the forward run process.
                     Default is 'gw'.
   :type gw_prefix: `str`, optional
   :param sw_prefix: a prefix to add to the SW budget observations.  Useful
                     if processing more than one list file as part of the forward run process.
                     Default is 'sw'.
   :type sw_prefix: `str`, optional
   :param save_setup_file: a flag to save "_setup_"+ `list_filename` +".csv" file
                           that contains useful control file information.  Default is `False`.
   :type save_setup_file: `bool`, optional

   :returns: tuple containing

             - **str**:  the command to add to the forward run script
             - **str**: the names of the instruction files that were created
             - **pandas.DataFrame**: a dataframe with information for constructing a control file

   .. note::

      writes an instruction file and also a _setup_.csv to use when constructing a pest
          control file
      
      the instruction files are named `out_filename` +".ins"
      
      It is recommended to use the default value for `gw_filename` or `sw_filename`.
      
      This is the companion function of `gw_utils.apply_mtlist_budget_obs()`.


.. function:: _write_mtlist_ins(ins_filename, df, prefix)

   write an instruction file for a MT3D-USGS list file



.. function:: apply_mtlist_budget_obs(list_filename, gw_filename='mtlist_gw.dat', sw_filename='mtlist_sw.dat', start_datetime='1-1-1970')

   process an MT3D-USGS list file to extract mass budget entries.

   :param list_filename: the path and name of an existing MT3D-USGS list file
   :type list_filename: `str`
   :param gw_filename: the name of the output file with gw mass
                       budget information. Default is "mtlist_gw.dat"
   :type gw_filename: `str`, optional
   :param sw_filename: the name of the output file with sw mass budget information.
                       Default is "mtlist_sw.dat"
   :type sw_filename: `str`
   :param start_datatime: an str that can be cast to a pandas.TimeStamp.  Used to give
                          observations a meaningful name
   :type start_datatime: `str`

   :returns: 2-element tuple containing

             - **pandas.DataFrame**: the gw mass budget dataframe
             - **pandas.DataFrame**: (optional) the sw mass budget dataframe.
               If the SFT process is not active, this returned value is `None`.

   .. note:: this is the companion function of `gw_utils.setup_mtlist_budget_obs()`.


.. function:: setup_mflist_budget_obs(list_filename, flx_filename='flux.dat', vol_filename='vol.dat', start_datetime="1-1'1970", prefix='', save_setup_file=False)

   setup observations of budget volume and flux from modflow list file.

   :param list_filename: path and name of the existing modflow list file
   :type list_filename: `str`
   :param flx_filename: output filename that will contain the budget flux
                        observations. Default is "flux.dat"
   :type flx_filename: `str`, optional
   :param vol_filename: output filename that will contain the budget volume
                        observations.  Default is "vol.dat"
   :type vol_filename: `str`, optional
   :param start_datetime: a string that can be parsed into a pandas.TimeStamp.
                          This is used to give budget observations meaningful names.  Default is "1-1-1970".
   :type start_datetime: `str`, optional
   :param prefix: a prefix to add to the water budget observations.  Useful if
                  processing more than one list file as part of the forward run process. Default is ''.
   :type prefix: `str`, optional
   :param save_setup_file: a flag to save "_setup_"+ `list_filename` +".csv" file that contains useful
                           control file information
   :type save_setup_file: `bool`

   :returns: a dataframe with information for constructing a control file.
   :rtype: **pandas.DataFrame**

   .. note::

      This method writes instruction files and also a _setup_.csv to use when constructing a pest
      control file.  The instruction files are named <flux_file>.ins and <vol_file>.ins, respectively
      
      It is recommended to use the default values for flux_file and vol_file.
      
      This is the companion function of `gw_utils.apply_mflist_budget_obs()`.


.. function:: apply_mflist_budget_obs(list_filename, flx_filename='flux.dat', vol_filename='vol.dat', start_datetime='1-1-1970')

   process a MODFLOW list file to extract flux and volume water budget entries.

   :param list_filename: path and name of the existing modflow list file
   :type list_filename: `str`
   :param flx_filename: output filename that will contain the budget flux
                        observations. Default is "flux.dat"
   :type flx_filename: `str`, optional
   :param vol_filename: output filename that will contain the budget volume
                        observations.  Default is "vol.dat"
   :type vol_filename: `str`, optional
   :param start_datetime: a string that can be parsed into a pandas.TimeStamp.
                          This is used to give budget observations meaningful names.  Default is "1-1-1970".
   :type start_datetime: `str`, optional
   :param prefix: a prefix to add to the water budget observations.  Useful if
                  processing more than one list file as part of the forward run process. Default is ''.
   :type prefix: `str`, optional
   :param save_setup_file: a flag to save _setup_<list_filename>.csv file that contains useful
                           control file information
   :type save_setup_file: `bool`

    Note:
        this is the companion function of `gw_utils.setup_mflist_budget_obs()`.

    Returns:
        tuple containing


        - **pandas.DataFrame**: a dataframe with flux budget information
        - **pandas.DataFrame**: a dataframe with cumulative budget information



.. function:: _write_mflist_ins(ins_filename, df, prefix)

   write an instruction file for a MODFLOW list file



.. function:: setup_hds_timeseries(bin_file, kij_dict, prefix=None, include_path=False, model=None, postprocess_inact=None, text=None, fill=None, precision='single')

   a function to setup a forward process to extract time-series style values
   from a binary modflow binary file (or equivalent format - hds, ucn, sub, cbb, etc).

   :param bin_file: path and name of existing modflow binary file - headsave, cell budget and MT3D UCN supported.
   :type bin_file: `str`
   :param kij_dict: dictionary of site_name: [k,i,j] pairs. For example: `{"wel1":[0,1,1]}`.
   :type kij_dict: `dict`
   :param prefix: string to prepend to site_name when forming observation names.  Default is None
   :type prefix: `str`, optional
   :param include_path: flag to setup the binary file processing in directory where the hds_file
                        is located (if different from where python is running).  This is useful for setting up
                        the process in separate directory for where python is running.
   :type include_path: `bool`, optional
   :param model: a `flopy.basemodel` instance.  If passed, the observation names will
                 have the datetime of the observation appended to them (using the flopy `start_datetime` attribute.
                 If None, the observation names will have the zero-based stress period appended to them. Default is None.
   :type model: `flopy.mbase`, optional
   :param postprocess_inact: Inactive value in heads/ucn file e.g. mt.btn.cinit.  If `None`, no
                             inactive value processing happens.  Default is `None`.
   :type postprocess_inact: `float`, optional
   :param text: the text record entry in the binary file (e.g. "constant_head").
                Used to indicate that the binary file is a MODFLOW cell-by-cell budget file.
                If None, headsave or MT3D unformatted concentration file
                is assummed.  Default is None
   :type text: `str`
   :param fill: fill value for NaNs in the extracted timeseries dataframe.  If
                `None`, no filling is done, which may yield model run failures as the resulting
                processed timeseries CSV file (produced at runtime) may have missing values and
                can't be processed with the cooresponding instruction file.  Default is `None`.
   :type fill: `float`
   :param precision: the precision of the binary file.  Can be "single" or "double".
                     Default is "single".
   :type precision: `str`

   :returns: tuple containing

             - **str**: the forward run command to execute the binary file process during model runs.

             - **pandas.DataFrame**: a dataframe of observation information for use in the pest control file

   .. note::

      This function writes hds_timeseries.config that must be in the same
      dir where `apply_hds_timeseries()` is called during the forward run
      
      Assumes model time units are days
      
      this is the companion function of `gw_utils.apply_hds_timeseries()`.


.. function:: apply_hds_timeseries(config_file=None, postprocess_inact=None)

   process a modflow binary file using a previously written
   configuration file

   :param config_file: configuration file written by `pyemu.gw_utils.setup_hds_timeseries`.
                       If `None`, looks for `hds_timeseries.config`
   :type config_file: `str`, optional
   :param postprocess_inact: Inactive value in heads/ucn file e.g. mt.btn.cinit.  If `None`, no
                             inactive value processing happens.  Default is `None`.
   :type postprocess_inact: `float`, optional

   .. note:: this is the companion function of `gw_utils.setup_hds_timeseries()`.


.. function:: _setup_postprocess_hds_timeseries(hds_file, df, config_file, prefix=None, model=None)

   Dirty function to setup post processing concentrations in inactive/dry cells


.. function:: _apply_postprocess_hds_timeseries(config_file=None, cinact=1e+30)

   private function to post processing binary files


.. function:: setup_hds_obs(hds_file, kperk_pairs=None, skip=None, prefix='hds', text='head', precision='single', include_path=False)

   a function to setup using all values from a layer-stress period
   pair for observations.

   :param hds_file: path and name of an existing MODFLOW head-save file.
                    If the hds_file endswith 'ucn', then the file is treated as a UcnFile type.
   :type hds_file: `str`
   :param kperk_pairs: a list of len two tuples which are pairs of kper
                       (zero-based stress period index) and k (zero-based layer index) to
                       setup observations for.  If None, then all layers and stress period records
                       found in the file will be used.  Caution: a shit-ton of observations may be produced!
   :type kperk_pairs: [(int,int)]
   :param skip: a value or function used to determine which values
                to skip when setting up observations.  If np.scalar(skip)
                is True, then values equal to skip will not be used.
                If skip can also be a np.ndarry with dimensions equal to the model.
                Observations are set up only for cells with Non-zero values in the array.
                If not np.ndarray or np.scalar(skip), then skip will be treated as a lambda function that
                returns np.NaN if the value should be skipped.
   :type skip: variable, optional
   :param prefix: the prefix to use for the observation names. default is "hds".
   :type prefix: `str`
   :param text: the text tag the flopy HeadFile instance.  Default is "head"
   :type text: `str`
   :param precison: the precision string for the flopy HeadFile instance.  Default is "single"
   :type precison: `str`
   :param include_path: flag to setup the binary file processing in directory where the hds_file
   :type include_path: `bool`, optional
   :param is located: the process in separate directory for where python is running.
   :type is located: if different from where python is running

   :returns: tuple containing

             - **str**: the forward run script line needed to execute the headsave file observation
               operation
             - **pandas.DataFrame**: a dataframe of pest control file information

   .. note::

      Writes an instruction file and a _setup_ csv used construct a control file.
      
      This is the companion function to `gw_utils.apply_hds_obs()`.


.. function:: last_kstp_from_kper(hds, kper)

   function to find the last time step (kstp) for a
   give stress period (kper) in a modflow head save file.

   :param hds: head save file
   :type hds: `flopy.utils.HeadFile`
   :param kper: the zero-index stress period number
   :type kper: `int`

   :returns: the zero-based last time step during stress period
             kper in the head save file
   :rtype: **int**


.. function:: apply_hds_obs(hds_file, inact_abs_val=1e+20, precision='single', text='head')

   process a modflow head save file.  A companion function to
   `gw_utils.setup_hds_obs()` that is called during the forward run process

   :param hds_file: a modflow head save filename. if hds_file ends with 'ucn',
                    then the file is treated as a UcnFile type.
   :type hds_file: `str`
   :param inact_abs_val: the value that marks the mininum and maximum
                         active value.  values in the headsave file greater than `inact_abs_val` or less
                         than -`inact_abs_val` are reset to `inact_abs_val`
   :type inact_abs_val: `float`, optional

   :returns: a dataframe with extracted simulated values.
   :rtype: **pandas.DataFrame**

   .. note:: This is the companion function to `gw_utils.setup_hds_obs()`.


.. function:: setup_sft_obs(sft_file, ins_file=None, start_datetime=None, times=None, ncomp=1)

   writes a post-processor and instruction file for a mt3d-usgs sft output file

   :param sft_file: path and name of an existing sft output file (ASCII)
   :type sft_file: `str`
   :param ins_file: the name of the instruction file to create.
                    If None, the name is `sft_file`+".ins".  Default is `None`.
   :type ins_file: `str`, optional
   :param start_datetime: a pandas.to_datetime() compatible str.  If not None,
                          then the resulting observation names have the datetime
                          suffix.  If None, the suffix is the output totim.  Default
                          is `None`.
   :type start_datetime: `str`
   :param times: a list of times to make observations for.  If None, all times
                 found in the file are used. Default is None.
   :type times: [`float`]
   :param ncomp: number of components in transport model. Default is 1.
   :type ncomp: `int`

   .. note:: this is the companion function to `gw_utils.apply_sft_obs()`.

   :returns: a dataframe with observation names and values for the sft simulated
             concentrations.
   :rtype: **pandas.DataFrame**


.. function:: apply_sft_obs()

   process an mt3d-usgs sft ASCII output file using a previous-written
   config file

   :returns: a dataframe of extracted simulated outputs
   :rtype: **pandas.DataFrame**

   .. note:: this is the companion function to `gw_utils.setup_sft_obs()`.


.. function:: setup_sfr_seg_parameters(nam_file, model_ws='.', par_cols=None, tie_hcond=True, include_temporal_pars=None)

   Setup multiplier parameters for SFR segment data.

   :param nam_file: MODFLOw name file.  DIS, BAS, and SFR must be
                    available as pathed in the nam_file.  Optionally, `nam_file` can be
                    an existing `flopy.modflow.Modflow`.
   :type nam_file: `str`
   :param model_ws: model workspace for flopy to load the MODFLOW model from
   :type model_ws: `str`
   :param par_cols: a list of segment data entires to parameterize
   :type par_cols: [`str`]
   :param tie_hcond: flag to use same mult par for hcond1 and hcond2 for a
                     given segment.  Default is `True`.
   :type tie_hcond: `bool`
   :param include_temporal_pars: list of spatially-global multipliers to set up for
                                 each stress period.  Default is None
   :type include_temporal_pars: [`str`]

   :returns: a dataframe with useful parameter setup information
   :rtype: **pandas.DataFrame**

   .. note::

      This function handles the standard input case, not all the cryptic SFR options.  Loads the
         dis, bas, and sfr files with flopy using model_ws.

       This is the companion function to `gw_utils.apply_sfr_seg_parameters()` .

       The number (and numbering) of segment data entries must consistent across
           all stress periods.

       Writes `nam_file` +"_backup_.sfr" as the backup of the original sfr file

       Skips values = 0.0 since multipliers don't work for these


.. function:: setup_sfr_reach_parameters(nam_file, model_ws='.', par_cols=['strhc1'])

   Setup multiplier paramters for reach data, when reachinput option is specififed in sfr.


   :param nam_file: MODFLOw name file.  DIS, BAS, and SFR must be
                    available as pathed in the nam_file.  Optionally, `nam_file` can be
                    an existing `flopy.modflow.Modflow`.
   :type nam_file: `str`
   :param model_ws: model workspace for flopy to load the MODFLOW model from
   :type model_ws: `str`
   :param par_cols: a list of segment data entires to parameterize
   :type par_cols: [`str`]
   :param tie_hcond: flag to use same mult par for hcond1 and hcond2 for a
                     given segment.  Default is `True`.
   :type tie_hcond: `bool`
   :param include_temporal_pars: list of spatially-global multipliers to set up for
                                 each stress period.  Default is None
   :type include_temporal_pars: [`str`]

   :returns: a dataframe with useful parameter setup information
   :rtype: **pandas.DataFrame**

   .. note::

      Similar to `gw_utils.setup_sfr_seg_parameters()`, method will apply params to sfr reachdata
      
      Can load the dis, bas, and sfr files with flopy using model_ws. Or can pass a model object
          (SFR loading can be slow)
      
      This is the companion function of `gw_utils.apply_sfr_reach_parameters()`
      
      Skips values = 0.0 since multipliers don't work for these


.. function:: apply_sfr_seg_parameters(seg_pars=True, reach_pars=False)

   apply the SFR segement multiplier parameters.

   :param seg_pars: flag to apply segment-based parameters.
                    Default is True
   :type seg_pars: `bool`, optional
   :param reach_pars: flag to apply reach-based parameters.
                      Default is False
   :type reach_pars: `bool`, optional

   :returns: the modified SFR package instance
   :rtype: **flopy.modflow.ModflowSfr**

   .. note::

      expects "sfr_seg_pars.config" to exist
      
      expects `nam_file` +"_backup_.sfr" to exist


.. function:: apply_sfr_parameters(seg_pars=True, reach_pars=False)

   thin wrapper around `gw_utils.apply_sfr_seg_parameters()`

   :param seg_pars: flag to apply segment-based parameters.
                    Default is True
   :type seg_pars: `bool`, optional
   :param reach_pars: flag to apply reach-based parameters.
                      Default is False
   :type reach_pars: `bool`, optional

   :returns: the modified SFR package instance
   :rtype: **flopy.modflow.ModflowSfr**

   .. note::

      expects "sfr_seg_pars.config" to exist
      
      expects `nam_file` +"_backup_.sfr" to exist


.. function:: setup_sfr_obs(sfr_out_file, seg_group_dict=None, ins_file=None, model=None, include_path=False)

   setup observations using the sfr ASCII output file.  Setups
   the ability to aggregate flows for groups of segments.  Applies
   only flow to aquier and flow out.

   :param sft_out_file: the name and path to an existing SFR output file
   :type sft_out_file: `str`
   :param seg_group_dict: a dictionary of SFR segements to aggregate together for a single obs.
                          the key value in the dict is the base observation name. If None, all segments
                          are used as individual observations. Default is None
   :type seg_group_dict: `dict`
   :param model: a flopy model.  If passed, the observation names will have
                 the datetime of the observation appended to them.  If None, the observation names
                 will have the stress period appended to them. Default is None.
   :type model: `flopy.mbase`
   :param include_path: flag to prepend sfr_out_file path to sfr_obs.config.  Useful for setting up
                        process in separate directory for where python is running.
   :type include_path: `bool`

   :returns: dataframe of observation name, simulated value and group.
   :rtype: **pandas.DataFrame**

   .. note::

      This is the companion function of `gw_utils.apply_sfr_obs()`.
      
      This function writes "sfr_obs.config" which must be kept in the dir where
      "gw_utils.apply_sfr_obs()" is being called during the forward run


.. function:: apply_sfr_obs()

   apply the sfr observation process

   .. note::

      This is the companion function of `gw_utils.setup_sfr_obs()`.
      
      requires `sfr_obs.config`.
      
      Writes `sfr_out_file`+".processed", where `sfr_out_file` is defined in "sfr_obs.config"

   :returns: a dataframe of aggregrated sfr segment aquifer and outflow
   :rtype: **pandas.DataFrame**


.. function:: load_sfr_out(sfr_out_file, selection=None)

   load an ASCII SFR output file into a dictionary of kper: dataframes.

   :param sfr_out_file: SFR ASCII output file
   :type sfr_out_file: `str`
   :param selection: a dataframe of `reach` and `segment` pairs to
                     load.  If `None`, all reach-segment pairs are loaded.  Default is `None`.
   :type selection: `pandas.DataFrame`

   .. note::

      aggregates flow to aquifer for segments and returns and flow out at
      downstream end of segment.

   :returns: dictionary of {kper:`pandas.DataFrame`} of SFR output.
   :rtype: **dict**


.. function:: setup_sfr_reach_obs(sfr_out_file, seg_reach=None, ins_file=None, model=None, include_path=False)

   setup observations using the sfr ASCII output file.  Setups
   sfr point observations using segment and reach numbers.

   :param sft_out_file: the path and name of an existing SFR output file
   :type sft_out_file: `str`
   :param seg_reach: a dict, or list of SFR [segment,reach] pairs identifying
                     locations of interest.  If `dict`, the key value in the dict is the base
                     observation name. If None, all reaches are used as individual observations.
                     Default is None - THIS MAY SET UP A LOT OF OBS!
   :type seg_reach: varies
   :param model: a flopy model.  If passed, the observation names will
                 have the datetime of the observation appended to them.  If None, the
                 observation names will have the stress period appended to them. Default is None.
   :type model: `flopy.mbase`
   :param include_path: a flag to prepend sfr_out_file path to sfr_obs.config.  Useful
                        for setting up process in separate directory for where python is running.
   :type include_path: `bool`

   :returns: a dataframe of observation names, values, and groups
   :rtype: `pd.DataFrame`

   .. note::

      This is the companion function of `gw_utils.apply_sfr_reach_obs()`.
      
      This function writes "sfr_reach_obs.config" which must be kept in the dir where
      "apply_sfr_reach_obs()" is being called during the forward run


.. function:: apply_sfr_reach_obs()

   apply the sfr reach observation process.

   .. note::

      This is the companion function of `gw_utils.setup_sfr_reach_obs()`.
      
      Requires sfr_reach_obs.config.
      
      Writes <sfr_out_file>.processed, where <sfr_out_file> is defined in
      "sfr_reach_obs.config"

   :returns: a dataframe of sfr aquifer and outflow ad segment,reach locations
   :rtype: `pd.DataFrame`


.. function:: modflow_sfr_gag_to_instruction_file(gage_output_file, ins_file=None, parse_filename=False)

   writes an instruction file for an SFR gage output file to read Flow only at all times

   :param gage_output_file: the gage output filename (ASCII).
   :type gage_output_file: `str`
   :param ins_file: the name of the instruction file to
                    create.  If None, the name is `gage_output_file` +".ins".
                    Default is None
   :type ins_file: `str`, optional
   :param parse_filename: if True, get the gage_num parameter by
                          parsing the gage output file filename if False, get the gage
                          number from the file itself
   :type parse_filename: `bool`

   :returns: tuple containing

             - **pandas.DataFrame**: a dataframe with obsnme and obsval for the sfr simulated flows.
             - **str**: file name of instructions file relating to gage output.
             - **str**: file name of processed gage output for all times

   .. note::

      sets up observations for gage outputs only for the Flow column.
      
      If `parse_namefile` is true, only text up to first '.' is used as the gage_num


.. function:: setup_gage_obs(gage_file, ins_file=None, start_datetime=None, times=None)

   setup a forward run post processor routine for the modflow gage file

   :param gage_file: the gage output file (ASCII)
   :type gage_file: `str`
   :param ins_file: the name of the instruction file to create.  If None, the name
                    is `gage_file`+".processed.ins".  Default is `None`
   :type ins_file: `str`, optional
   :param start_datetime: a `pandas.to_datetime()` compatible `str`.  If not `None`,
                          then the resulting observation names have the datetime suffix.  If `None`,
                          the suffix is the output totim.  Default is `None`.
   :type start_datetime: `str`
   :param times: a container of times to make observations for.  If None,
                 all times are used. Default is None.
   :type times: [`float`]

   :returns: tuple containing

             - **pandas.DataFrame**: a dataframe with observation name and simulated values for the
               values in the gage file.
             - **str**: file name of instructions file that was created relating to gage output.
             - **str**: file name of processed gage output (processed according to times passed above.)

   .. note::

      setups up observations for gage outputs (all columns).
      
      This is the companion function of `gw_utils.apply_gage_obs()`


.. function:: apply_gage_obs(return_obs_file=False)

   apply the modflow gage obs post-processor

   :param return_obs_file: flag to return the processed
                           observation file.  Default is `False`.
   :type return_obs_file: `bool`

   .. note:: This is the companion function of `gw_utils.setup_gage_obs()`


.. function:: apply_hfb_pars(par_file='hfb6_pars.csv')

   a function to apply HFB multiplier parameters.

   :param par_file: the HFB parameter info file.
                    Default is `hfb_pars.csv`
   :type par_file: `str`

   .. note::

      This is the companion function to
      `gw_utils.write_hfb_zone_multipliers_template()`
      
      This is to account for the horrible HFB6 format that differs from other
      BCs making this a special case
      
      Requires "hfb_pars.csv"
      
      Should be added to the forward_run.py script


.. function:: write_hfb_zone_multipliers_template(m)

   write a template file for an hfb using multipliers per zone (double yuck!)

   :param m: a model instance with an HFB package
   :type m: `flopy.modflow.Modflow`

   :returns: tuple containing

             - **dict**: a dictionary with original unique HFB conductivity values and their
               corresponding parameter names
             - **str**: the template filename that was created


.. function:: write_hfb_template(m)

   write a template file for an hfb (yuck!)

   :param m: a model instance with an HFB package
   :type m: `flopy.modflow.Modflow`

    Returns:
        tuple containing

        - **str**: name of the template file that was created

        - **pandas.DataFrame**: a dataframe with use control file info for the
          HFB parameters



.. py:exception:: PyemuWarning

   Bases: :class:`RuntimeWarning`

   Base class for warnings about dubious runtime behavior.


.. data:: ext
   :annotation: = 

   

.. data:: bin_path
   

   

.. function:: _istextfile(filename, blocksize=512)

   Function found from:
   https://eli.thegreenplace.net/2011/10/19/perls-guess-if-file-is-text-or-binary-implemented-in-python
   Returns True if file is most likely a text file
   Returns False if file is most likely a binary file
   Uses heuristics to guess whether the given file is text or binary,
   by reading a single block of bytes from the file.
   If more than 30% of the chars in the block are non-text, or there
   are NUL (' ') bytes in the block, assume this is a binary file.


.. function:: _remove_readonly(func, path, excinfo)

   remove readonly dirs, apparently only a windows issue
   add to all rmtree calls: shutil.rmtree(**,onerror=remove_readonly), wk


.. function:: run(cmd_str, cwd='.', verbose=False)

   an OS agnostic function to execute a command line

   :param cmd_str: the str to execute with `os.system()`
   :type cmd_str: `str`
   :param cwd: the directory to execute the command in.
               Default is ".".
   :type cwd: `str`, optional
   :param verbose: flag to echo to stdout the  `cmd_str`.
                   Default is `False`.
   :type verbose: `bool`, optional

   .. rubric:: Notes

   uses `platform` to detect OS and adds .exe suffix or ./ prefix as appropriate
   if `os.system` returns non-zero, an exception is raised

   Example::

       pyemu.os_utils.run("pestpp-ies my.pst",cwd="template")


.. function:: start_workers(worker_dir, exe_rel_path, pst_rel_path, num_workers=None, worker_root='..', port=4004, rel_path=None, local=True, cleanup=True, master_dir=None, verbose=False, silent_master=False, reuse_master=False)

   start a group of pest(++) workers on the local machine

   :param worker_dir: the path to a complete set of input files need by PEST(++).
                      This directory will be copied to make worker (and optionally the master)
                      directories
   :type worker_dir: `str`
   :param exe_rel_path: the relative path to and name of the pest(++) executable from within
                        the `worker_dir`.  For example, if the executable is up one directory from
                        `worker_dir`, the `exe_rel_path` would be `os.path.join("..","pestpp-ies")`
   :type exe_rel_path: `str`
   :param pst_rel_path: the relative path to and name of the pest control file from within
                        `worker_dir`.
   :type pst_rel_path: `str`
   :param num_workers: number of workers to start. defaults to number of cores
   :type num_workers: `int`, optional
   :param worker_root: the root directory to make the new worker directories in.
                       Default is ".."  (up one directory from where python is running).
   :type worker_root: `str`, optional
   :param rel_path: the relative path to where pest(++) should be run
                    from within the worker_dir, defaults to the uppermost level of the worker dir.
                    This option is usually not needed unless you are one of those crazy people who
                    spreads files across countless subdirectories.
   :type rel_path: `str`, optional
   :param local: flag for using "localhost" instead of actual hostname/IP address on
                 worker command line. Default is True
   :type local: `bool`, optional
   :param cleanup: flag to remove worker directories once processes exit. Default is
                   True.  Set to False for debugging issues
   :type cleanup: `bool`, optional
   :param master_dir: name of directory for master instance.  If `master_dir`
                      exists, then it will be REMOVED!!!  If `master_dir`, is None,
                      no master instance will be started.  If not None, a copy of `worker_dir` will be
                      made into `master_dir` and the PEST(++) executable will be started in master mode
                      in this directory. Default is None
   :type master_dir: `str`
   :param verbose: flag to echo useful information to stdout.  Default is False
   :type verbose: `bool`, optional
   :param silent_master: flag to pipe master output to devnull and instead print
                         a simple message to stdout every few seconds.  This is only for
                         pestpp Travis testing so that log file sizes dont explode. Default is False
   :type silent_master: `bool`, optional
   :param reuse_master: flag to use an existing `master_dir` as is - this is an advanced user
                        option for cases where you want to construct your own `master_dir` then have an async
                        process started in it by this function.
   :type reuse_master: `bool`

   .. rubric:: Notes

   if all workers (and optionally master) exit gracefully, then the worker
       dirs will be removed unless `cleanup` is False

   Example::

       # start 10 workers using the directory "template" as the base case and
       # also start a master instance in a directory "master".
       pyemu.helpers.start_workers("template","pestpp-ies","pest.pst",10,master_dir="master")


.. py:exception:: PyemuWarning

   Bases: :class:`RuntimeWarning`

   Base class for warnings about dubious runtime behavior.


.. function:: smp_to_ins(smp_filename, ins_filename=None, use_generic_names=False, gwutils_compliant=False, datetime_format=None, prefix='')

   create an instruction file for an smp file

   :param smp_filename: path and name of an existing smp file
   :type smp_filename: `str`
   :param ins_filename: the name of the instruction
                        file to create.  If None, `smp_filename` +".ins" is used.
                        Default is None.
   :type ins_filename: `str`, optional
   :param use_generic_names: flag to force observations names
                             to use a generic `int` counter instead of trying to use a
                             datetime string.  Default is False
   :type use_generic_names: `bool`
   :param gwutils_compliant: flag to use instruction set that
                             is compliant with the PEST gw utils (fixed format instructions).
                             If false, use free format (with whitespace) instruction set.
                             Default is False
   :type gwutils_compliant: `bool`
   :param datetime_format: string to pass to datetime.strptime in
                           the `smp_utils.smp_to_dataframe()` function.  If None, not
                           used. Default is None.
   :type datetime_format: `str`
   :param prefix: a prefix to add to the front of the derived
                  observation names.  Default is ''
   :type prefix: `str`

   :returns: a dataframe of the smp file
             information with the observation names and
             instruction lines as additional columns.
   :rtype: `pandas.DataFrame`

   Example::

       df = pyemu.smp_utils.smp_to_ins("my.smp")


.. function:: dataframe_to_smp(dataframe, smp_filename, name_col='name', datetime_col='datetime', value_col='value', datetime_format='dd/mm/yyyy', value_format='{0:15.6E}', max_name_len=12)

   write a dataframe as an smp file

   :param dataframe: the dataframe to write to an SMP
                     file.  This dataframe should be in "long" form - columns for
                     site name, datetime, and value.
   :type dataframe: `pandas.DataFrame`
   :param smp_filename: smp file to write
   :type smp_filename: `str`
   :param name_col: the name of the dataframe column
                    that contains the site name.  Default is "name"
   :type name_col: `str`,optional
   :param datetime_col: the column in the dataframe that the
                        datetime values.  Default is "datetime".
   :type datetime_col: `str`
   :param value_col: the column in the dataframe that is the values
   :type value_col: `str`
   :param datetime_format: The format to write the datetimes in the
                           smp file.  Can be either 'dd/mm/yyyy' or 'mm/dd/yyy'.  Default
                           is 'dd/mm/yyyy'.
   :type datetime_format: `str`, optional
   :param value_format: a python float-compatible format.
                        Default is "{0:15.6E}".
   :type value_format: `str`, optional

   Example::

       pyemu.smp_utils.dataframe_to_smp(df,"my.smp")


.. function:: _date_parser(items)

   datetime parser to help load smp files


.. function:: smp_to_dataframe(smp_filename, datetime_format=None)

   load an smp file into a pandas dataframe

   :param smp_filename: path and nane of existing smp filename to load
   :type smp_filename: `str`
   :param datetime_format: The format of the datetime strings
                           in the smp file. Can be either "%m/%d/%Y %H:%M:%S" or "%d/%m/%Y %H:%M:%S"
                           If None, then we will try to deduce the format for you, which
                           always dangerous.
   :type datetime_format: `str`, optional

   :returns: a dataframe with index of datetime and columns of
             site names.  Missing values are set to NaN.
   :rtype: `pandas.DataFrame`

   Example::

       df = smp_to_dataframe("my.smp")


.. py:exception:: PyemuWarning

   Bases: :class:`RuntimeWarning`

   Base class for warnings about dubious runtime behavior.


.. function:: _get_datetime_from_str(sdt)


.. function:: _check_var_len(var, n, fill=None)


.. py:class:: PstFrom(original_d, new_d, longnames=True, remove_existing=False, spatial_reference=None, zero_based=True, start_datetime=None)

   Bases: :class:`object`

   construct high-dimensional PEST(++) interfaces with all the bells and whistles

   :param original_d: the path to a complete set of model input and output files
   :type original_d: `str`
   :param new_d: the path to where the model files and PEST interface files will be copied/built
   :type new_d: `str`
   :param longnames: flag to use longer-than-PEST-likes parameter and observation names.  Default is True
   :type longnames: `bool`
   :param remove_existing: flag to destroy any existing files and folders in `new_d`.  Default is False
   :type remove_existing: `bool`
   :param spatial_reference: an object that faciliates geo-locating model cells based on index.  Default is None
   :type spatial_reference: varies
   :param zero_based: flag if the model uses zero-based indices, Default is True
   :type zero_based: `bool`
   :param start_datetime: a string that can be case to a datatime instance the represents the starting datetime
                          of the model
   :type start_datetime: `str`

   .. method:: parfile_relations(self)
      :property:


   .. method:: _generic_get_xy(self, args, **kwargs)


   .. method:: _flopy_sr_get_xy(self, args, **kwargs)


   .. method:: _flopy_mg_get_xy(self, args, **kwargs)


   .. method:: parse_kij_args(self, args, kwargs)

      parse args into kij indices


   .. method:: initialize_spatial_reference(self)

      process the spatial reference argument


   .. method:: write_forward_run(self)

      write the forward run script



   .. method:: _pivot_par_struct_dict(self)


   .. method:: build_prior(self, fmt='ascii', filename=None, droptol=None, chunk=None, sigma_range=6)

      Build the prior parameter covariance matrix

      :param fmt: the file format to save to.  Default is "ASCII", can be "binary", "coo", or "none"
      :type fmt: `str`
      :param filename: the filename to save the cov to
      :type filename: `str`
      :param droptol: absolute value of prior cov entries that are smaller than `droptol` are treated as
                      zero.
      :type droptol: `float`
      :param chunk: number of entries to write to binary/coo at once.  Default is None (write all elements at once
      :type chunk: `int`
      :param sigma_range: number of standard deviations represented by parameter bounds.  Default is 6 (99%
                          confidence).  4 would be approximately 95% confidence bounds
      :type sigma_range: `int`

      :returns: the prior parameter covariance matrix
      :rtype: `pyemu.Cov`

      .. note:: This method processes parameters by group names


   .. method:: draw(self, num_reals=100, sigma_range=6, use_specsim=False, scale_offset=True)

      Draw a parameter ensemble from the distribution implied by the initial parameter values in the
      control file and the prior parameter covariance matrix.

      :param num_reals: the number of realizations to draw
      :type num_reals: `int`
      :param sigma_range: number of standard deviations represented by parameter bounds.  Default is 6 (99%
                          confidence).  4 would be approximately 95% confidence bounds
      :type sigma_range: `int`
      :param use_specsim: flag to use spectral simulation for grid-scale pars (highly recommended).
                          Default is False
      :type use_specsim: `bool`
      :param scale_offset: flag to apply scale and offset to parameter bounds before calculating prior variance.
                           Dfault is True
      :type scale_offset: `bool`

      :returns: a prior parameter ensemble
      :rtype: `pyemu.ParameterEnsemble`

      .. note:: This method draws by parameter group


   .. method:: build_pst(self, filename=None, update=False, version=1)

      Build control file from i/o files in PstFrom object.
      Warning: This builds a pest control file from scratch, overwriting
      anything already in self.pst object and anything already writen to `filename`

      :param filename: the filename to save the control file to.
                       If None, the name is formed from the `PstFrom.original_d`
                       ,the orginal directory name from which the forward model
                       was extracted.  Default is None.
                       The control file is saved in the `PstFrom.new_d` directory.
      :type filename: `str`
      :param update: flag to add to existing Pst object and
                     rewrite. If string {'pars', 'obs'} just update respective
                     components of Pst. Default is False - build from PstFrom
                     components.
      :type update: bool) or (str

      .. note::

         This builds a pest control file from scratch, overwriting anything already
             in self.pst object and anything already writen to `filename`


   .. method:: _setup_dirs(self)


   .. method:: _par_prep(self, filenames, index_cols, use_cols, fmts=None, seps=None, skip_rows=None, c_char=None)


   .. method:: _next_count(self, prefix)


   .. method:: add_py_function(self, file_name, function_name, is_pre_cmd=True)

      add a python function to the forward run script

      :param file_name: a python source file
      :type file_name: `str`
      :param function_name: a python function in
                            `file_name`
      :type function_name: `str`
      :param is_pre_cmd: flag to include `function_name` in
                         PstFrom.pre_py_cmds.  If False, `function_name` is
                         added to PstFrom.post_py_cmds instead. If passed as `None`,
                         then the function `function_name` is added to the forward run
                         script but is not called.  Default is True.
      :type is_pre_cmd: `bool`

      :returns: None

      .. note::

         `function_name` is expected to be standalone a function
             that contains all the imports it needs or these imports
             should have been added to the forward run script through the
             `PstFrom.py_imports` list.
         This function adds the `function_name` call to the forward
             run script (either as a pre or post command). It is up to users
              to make sure `function_name` is a valid python function call
               that includes the parentheses and requisite arguments
         This function expects "def " + `function_name` to be flushed left at the outer
             most indentation level

      Example::

          pf = PstFrom()
          pf.add_py_function("preprocess.py","mult_well_function()",is_pre_cmd=True)



   .. method:: add_observations(self, filename, insfile=None, index_cols=None, use_cols=None, use_rows=None, prefix='', ofile_skip=None, ofile_sep=None, rebuild_pst=False, obsgp=True)

      Add list style outputs as observation files to PstFrom object

      :param filename: path to model output file name to set up
                       as observations
      :type filename: `str`
      :param insfile: desired instructions file filename
      :type insfile: `str`
      :param index_cols: columns to denote are indices for obs
      :type index_cols: `list`-like or `int`
      :param use_cols: columns to set up as obs
      :type use_cols: `list`-like or `int`
      :param use_rows: select only specific row of file for obs
      :type use_rows: `list`-like or `int`
      :param prefix: prefix for obsnmes
      :type prefix: `str`
      :param ofile_skip: number of lines to skip in model output file
      :type ofile_skip: `int`
      :param ofile_sep: delimiter in output file
      :type ofile_sep: `str`
      :param rebuild_pst: (Re)Construct PstFrom.pst object after adding
                          new obs
      :type rebuild_pst: `bool`

      :returns: dataframe with info for new observations
      :rtype: `Pandas.DataFrame`


   .. method:: add_observations_from_ins(self, ins_file, out_file=None, pst_path=None, inschek=True)

      add new observations to a control file

      :param ins_file: instruction file with exclusively new
                       observation names
      :type ins_file: `str`
      :param out_file: model output file.  If None, then
                       ins_file.replace(".ins","") is used. Default is None
      :type out_file: `str`
      :param pst_path: the path to append to the instruction file and
                       out file in the control file.  If not None, then any existing
                       path in front of the template or in file is split off and
                       pst_path is prepended.  If python is being run in a directory
                       other than where the control file will reside, it is useful
                       to pass `pst_path` as `.`. Default is None
      :type pst_path: `str`
      :param inschek: flag to try to process the existing output file
                      using the `pyemu.InstructionFile` class.  If successful,
                      processed outputs are used as obsvals
      :type inschek: `bool`

      :returns:

                the data for the new observations that were
                   added
      :rtype: `pandas.DataFrame`

      .. note:: populates the new observation information with default values

      Example::

          pst = pyemu.Pst(os.path.join("template", "my.pst"))
          pst.add_observations(os.path.join("template","new_obs.dat.ins"),
                               pst_path=".")
          pst.write(os.path.join("template", "my_new.pst")


   .. method:: add_parameters(self, filenames, par_type, zone_array=None, dist_type='gaussian', sigma_range=4.0, upper_bound=10000000000.0, lower_bound=1e-10, transform='log', par_name_base='p', index_cols=None, use_cols=None, pargp=None, pp_space=10, use_pp_zones=False, num_eig_kl=100, spatial_reference=None, geostruct=None, datetime=None, mfile_fmt='free', mfile_skip=None, ult_ubound=None, ult_lbound=None, rebuild_pst=False, alt_inst_str='inst', comment_char=None, par_style='multiplier')

      Add list or array style model input files to PstFrom object.
      This method

      :param filenames: Model input filenames to parameterize
      :type filenames: `str`
      :param par_type: One of `grid` - for every element, `constant` - for single
                       parameter applied to every element, `zone` - for zone-based
                       parameterization (only for array-style) or `pilotpoint` - for
                       pilot-point base parameterization of array style input files.
                       Note `kl` not yet implemented # TODO
      :type par_type: `str`
      :param zone_array: array defining spatial limits or zones
                         for parameterization.
      :type zone_array: `np.ndarray`
      :param dist_type: not yet implemented # TODO
      :param sigma_range: not yet implemented # TODO
      :param upper_bound: PEST parameter upper bound # TODO support different ubound,lbound,transform if multiple use_col
      :type upper_bound: `float`
      :param lower_bound: PEST parameter lower bound
      :type lower_bound: `float`
      :param transform: PEST parameter transformation
      :type transform: `str`
      :param par_name_base: basename for parameters that are set up
      :type par_name_base: `str`
      :param index_cols: if not None, will attempt to parameterize
                         expecting a tabular-style model input file. `index_cols`
                         defines the unique columns used to set up pars.
                         May be passed as a dictionary using the keys `i` and `j`
                         to allow columns that relate to model rows and columns to be
                         identified and processed to x,y.
      :type index_cols: `list`-like
      :param use_cols: for tabular-style model input file,
                       defines the columns to be parameterised
      :type use_cols: `list`-like or `int`
      :param pargp: Parameter group to assign pars to. This is PESTs
                    pargp but is also used to gather correlated parameters set up
                    using multiple `add_parameters()` calls (e.g. temporal pars)
                    with common geostructs.
      :type pargp: `str`
      :param pp_space: Spacing between pilot point parameters
      :type pp_space: `int`
      :param use_pp_zones: a flag to use the greater-than-zero values
                           in the zone_array as pilot point zones.
                           If False, zone_array values greater than zero are treated as a
                           single zone.  Default is False.
      :type use_pp_zones: `bool`
      :param num_eig_kl: TODO - impliment with KL pars
      :param spatial_reference: If different
                                spatial reference required for pilotpoint setup.
                                If None spatial reference passed to `PstFrom()` will be used
                                for pilot-points
      :type spatial_reference: `pyemu.helpers.SpatialReference`
      :param geostruct: For specifying correlation
                        geostruct for pilot-points and par covariance.
      :type geostruct: `pyemu.geostats.GeoStruct()`
      :param datetime: optional %Y%m%d string or datetime object for
                       setting up temporally correlated pars. Where datetime is passed
                        correlation axis for pars will be set to timedelta.
      :type datetime: `str`
      :param mfile_fmt: format of model input file - this will be preserved
      :type mfile_fmt: `str`
      :param mfile_skip: header in model input file to skip
                         when reading and reapply when writing. Can optionally be `str` in which case `mf_skip` will be treated
                         as a `comment_char`.
      :type mfile_skip: `int` or `str`
      :param ult_ubound: Ultimate upper bound for model input
                         parameter once all mults are applied - ensure physical model par vals. If not passed,
                         it is set to 1.0e+30
      :type ult_ubound: `float`
      :param ult_lbound: Ultimate lower bound for model input
                         parameter once all mults are applied.  If not passed, it is set to
                         1.0e-30 for log transform and -1.0e+30 for non-log transform
      :type ult_lbound: `float`
      :param rebuild_pst: (Re)Construct PstFrom.pst object after adding
                          new parameters
      :type rebuild_pst: `bool`
      :param alt_inst_str: Alternative to default `inst` string in
                           parameter names
      :type alt_inst_str: `str`
      :param comment_char: option to skip comment lines in model file.
                           This is not additive with `mfile_skip` option.
                           Warning: currently comment lines within list-like tabular data
                           will be lost.
      :type comment_char: `str`
      :param par_style: either "multiplier" or "direct" where the former setups
                        up a multiplier parameter process against the exsting model input
                        array and the former setups a template file to write the model
                        input file directly.  Default is "multiplier".
      :type par_style: `str`

      :returns: dataframe with info for new parameters
      :rtype: `pandas.DataFrame`


   .. method:: _load_listtype_file(self, filename, index_cols, use_cols, fmt=None, sep=None, skip=None, c_char=None)


   .. method:: _prep_arg_list_lengths(self, filenames, fmts=None, seps=None, skip_rows=None, index_cols=None, use_cols=None)

      Private wrapper function to align filenames, formats, delimiters,
      reading options and setup columns for passing sequentially to
      load_listtype
      :param filenames: names for files ot eventually read
      :type filenames: `str`) or (`list`
      :param fmts: of column formaters for input file.
                   If `None`, free-formatting is assumed
      :type fmts: `str`) or (`list`
      :param seps: column separator free formatter files.
                   If `None`, a list of `None`s is returned and the delimiter
                   is eventually governed by the file extension (`,` for .csv)
      :type seps: `str`) or (`list`
      :param skip_rows: Number of rows in file header to not
                        form part of the dataframe
      :type skip_rows: `str`) or (`list`
      :param index_cols: Columns in tabular file to use as indicies
      :type index_cols: `int`) or (`list`
      :param use_cols: Columns in tabular file to
                       use as par or obs cols
      :type use_cols: `int`) or (`list`

      :returns: filenames, fmts, seps, skip_rows, index_cols, use_cols
                for squentially passing to `_load_listtype_file()`
      :rtype: algined lists of



.. function:: write_list_tpl(filenames, dfs, name, tpl_filename, index_cols, par_type, use_cols=None, suffix='', zone_array=None, gpname=None, longnames=False, get_xy=None, ij_in_idx=None, xy_in_idx=None, zero_based=True, input_filename=None, par_style='multiplier')

   Write template files for a list style input.

   :param filenames: original input filenames
   :type filenames: `str` of `container` of `str`
   :param dfs: pandas
               representations of input file.
   :type dfs: `pandas.DataFrame` or `container` of pandas.DataFrames
   :param name: parameter name prefixes.
                If more that one column to be parameterised, must be a container
                of strings providing the prefix for the parameters in the
                different columns.
   :type name: `str` or container of str
   :param tpl_filename: Path (from current execution directory)
                        for desired template file
   :type tpl_filename: `str`
   :param index_cols: column names to use as indices in tabular
                      input dataframe
   :type index_cols: `list`
   :param par_type: 'constant','zone', or 'grid' used in parname
                    generation. If `constant`, one par is set up for each `use_cols`.
                    If `zone`, one par is set up for each zone for each `use_cols`.
                    If `grid`, one par is set up for every unique index combination
                    (from `index_cols`) for each `use_cols`.
   :type par_type: `str`
   :param use_cols: Columns in tabular input file to paramerterise.
                    If None, pars are set up for all columns apart from index cols.
   :type use_cols: `list`
   :param suffix: Optional par name suffix
   :type suffix: `str`
   :param zone_array: Array defining zone divisions.
                      If not None and `par_type` is `grid` or `zone` it is expected that
                      `index_cols` provide the indicies for
                      querying `zone_array`. Therefore, array dimension should equal
                      `len(index_cols)`.
   :type zone_array: `np.ndarray`
   :param longnames: Specify is pars will be specified without the
                     12 char restriction - recommended if using Pest++.
   :type longnames: `boolean`
   :param get_xy: Can be specified to get real-world xy
                  from `index_cols` passed (to assist correlation definition)
   :type get_xy: `pyemu.PstFrom` method
   :param ij_in_idx: defining which `index_cols` contain i,j
   :type ij_in_idx: `list` or `array`
   :param xy_in_idx: defining which `index_cols` contain x,y
   :type xy_in_idx: `list` or `array`
   :param zero_based: IMPORTANT - pass as False if `index_cols`
                      are NOT zero-based indicies (e.g. MODFLOW row/cols).
                      If False 1 with be subtracted from `index_cols`.
   :type zero_based: `boolean`
   :param input_filename: Path to input file (paired with tpl file)
   :type input_filename: `str`
   :param par_style: either 'direct' or 'multiplier'
   :type par_style: `str`

   :returns: dataframe with info for the new parameters
   :rtype: `pandas.DataFrame`


.. function:: _write_direct_df_tpl(in_filename, tpl_filename, df, name, index_cols, typ, use_cols=None, suffix='', zone_array=None, longnames=False, get_xy=None, ij_in_idx=None, xy_in_idx=None, zero_based=True, gpname=None)

   Private method to auto-generate parameter or obs names from tabular
   model files (input or output) read into pandas dataframes
   :param tpl_filename: template filename
   :type tpl_filename: `str`
   :param df: DataFrame of list type input file
   :type df: `pandas.DataFrame`
   :param name: Parameter name prefix
   :type name: `str`
   :param index_cols: columns of dataframes to use as indicies
   :type index_cols: `str` or `list`
   :param typ: 'constant','zone', or 'grid' used in parname generation.
               If `constant`, one par is set up for each `use_cols`.
               If `zone`, one par is set up for each zone for each `use_cols`.
               If `grid`, one par is set up for every unique index combination
               (from `index_cols`) for each `use_cols`.
   :type typ: `str`
   :param use_cols: Columns to parameterise. If None, pars are set up
                    for all columns apart from index cols
   :type use_cols: `list`
   :param suffix: Optional par name suffix.
   :type suffix: `str`
   :param zone_array: Array defining zone divisions.
                      If not None and `par_type` is `grid` or `zone` it is expected that
                      `index_cols` provide the indicies for querying `zone_array`.
                      Therefore, array dimension should equal `len(index_cols)`.
   :type zone_array: `np.ndarray`
   :param longnames: Specify is obs/pars will be specified without the
                     20/12 char restriction - recommended if using Pest++.
   :type longnames: `boolean`
   :param get_xy: Can be specified to get real-world xy
                  from `index_cols` passed (to include in obs/par name)
   :type get_xy: `pyemu.PstFrom` method
   :param ij_in_idx: defining which `index_cols` contain i,j
   :type ij_in_idx: `list` or `array`
   :param xy_in_idx: defining which `index_cols` contain x,y
   :type xy_in_idx: `list` or `array`
   :param zero_based: IMPORTANT - pass as False if `index_cols`
                      are NOT zero-based indicies (e.g. MODFLOW row/cols).
                      If False 1 with be subtracted from `index_cols`.
   :type zero_based: `boolean`

   :returns: pandas.DataFrame with paranme and pargroup define for each `use_col`


.. function:: _get_tpl_or_ins_df(filenames, dfs, name, index_cols, typ, use_cols=None, suffix='', zone_array=None, longnames=False, get_xy=None, ij_in_idx=None, xy_in_idx=None, zero_based=True, gpname=None)

   Private method to auto-generate parameter or obs names from tabular
   model files (input or output) read into pandas dataframes
   :param filenames: filenames
   :type filenames: `str` or `list` of str`
   :param dfs: DataFrames (can be list of DataFrames)
               to set up parameters or observations
   :type dfs: `pandas.DataFrame` or `list`
   :param name: Parameter name or Observation name prefix
   :type name: `str`
   :param index_cols: columns of dataframes to use as indicies
   :type index_cols: `str` or `list`
   :param typ: 'obs' to set up observation names or,
               'constant','zone', or 'grid' used in parname generation.
               If `constant`, one par is set up for each `use_cols`.
               If `zone`, one par is set up for each zone for each `use_cols`.
               If `grid`, one par is set up for every unique index combination
               (from `index_cols`) for each `use_cols`.
   :type typ: `str`
   :param use_cols: Columns to parameterise. If None, pars are set up
                    for all columns apart from index cols. Not used if `typ`==`obs`.
   :type use_cols: `list`
   :param suffix: Optional par name suffix. Not used if `typ`==`obs`.
   :type suffix: `str`
   :param zone_array: Only used for paremeters (`typ` != `obs`).
                      Array defining zone divisions.
                      If not None and `par_type` is `grid` or `zone` it is expected that
                      `index_cols` provide the indicies for querying `zone_array`.
                      Therefore, array dimension should equal `len(index_cols)`.
   :type zone_array: `np.ndarray`
   :param longnames: Specify is obs/pars will be specified without the
                     20/12 char restriction - recommended if using Pest++.
   :type longnames: `boolean`
   :param get_xy: Can be specified to get real-world xy
                  from `index_cols` passed (to include in obs/par name)
   :type get_xy: `pyemu.PstFrom` method
   :param ij_in_idx: defining which `index_cols` contain i,j
   :type ij_in_idx: `list` or `array`
   :param xy_in_idx: defining which `index_cols` contain x,y
   :type xy_in_idx: `list` or `array`
   :param zero_based: IMPORTANT - pass as False if `index_cols`
                      are NOT zero-based indicies (e.g. MODFLOW row/cols).
                      If False 1 with be subtracted from `index_cols`.=
   :type zero_based: `boolean`

   :returns: pandas.DataFrame with index strings for setting up obs
             names when passing through to
             pyemu.pst_utils.csv_to_ins_file(df.set_index('idx_str')

             else: pandas.DataFrame with paranme and pargroup define for each `use_col`
   :rtype: if `typ`==`obs`


.. function:: write_array_tpl(name, tpl_filename, suffix, par_type, zone_array=None, gpname=None, shape=None, longnames=False, fill_value=1.0, get_xy=None, input_filename=None, par_style='multiplier')

   write a template file for a 2D array.

    Args:
       name (`str`): the base parameter name
       tpl_filename (`str`): the template file to write - include path
       suffix (`str`): suffix to append to par names
       par_type (`str`): type of parameter
       zone_array (`numpy.ndarray`): an array used to skip inactive cells. Values less than 1 are
           not parameterized and are assigned a value of fill_value. Default is None.
       gpname (`str`): pargp filed in dataframe
       shape (`tuple`): dimensions of array to write
       longnames (`bool`): Use parnames > 12 char
       fill_value:
       get_xy:
       input_filename:
       par_style (`str`): either 'direct' or 'multiplier'

   :returns: a dataframe with parameter information
   :rtype: df (`pandas.DataFrame`)


.. function:: _check_diff(org_arr, input_filename, zval=None)


